{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# SharedMemoryDataLoader Demo & Benchmark\n",
    "\n",
    "This notebook demonstrates how to use the SharedMemoryDataLoader and runs a small benchmark to test its performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "import time\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom IPython.display import display, clear_output\n\n# Use the new factory pattern!\nfrom data_loader import actvs_loader_from_test_config"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Much simpler with factory pattern!\n# No need to manually configure - the factory handles it all\n\nbatch_size = 1000  # Smaller batch size for demo\n\nprint(\"üìã Using test configuration with factory pattern\")\nprint(f\"   Batch size: {batch_size}\")\nprint(\"   Buffer size: 100,000 samples\") \nprint(\"   Generation batch size: 2\")\n"
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 3. Create and Initialize the DataLoader\n",
    "\n",
    "Let's create the SharedMemoryDataLoader and wait for it to initialize.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": "print(\"üöÄ Creating SharedMemoryDataLoader with factory pattern...\")\nprint(\"   All IO and process starting happens at the top level - much cleaner!\")\n\n# One-line creation with factory pattern! Process starts immediately.\nloader = actvs_loader_from_test_config(batch_size=batch_size)\n\nprint(\"   ‚úÖ DataLoader created and process started!\")\nprint(\"   Ready to load data immediately - no waiting needed!\")",
   "outputs": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait a bit for buffer to fill\n",
    "time.sleep(10)\n",
    "\n",
    "print(\"üì¶ Loading first batch...\")\n",
    "try:\n",
    "    # Load first batch\n",
    "    batch = next(iter(loader))\n",
    "    \n",
    "    print(f\"‚úÖ Successfully loaded batch!\")\n",
    "    print(f\"   Shape: {batch.shape}\")\n",
    "    print(f\"   Data type: {batch.dtype}\")\n",
    "    print(f\"   Device: {batch.device}\")\n",
    "    print(f\"   Memory usage: {batch.numel() * batch.element_size() / 1024 / 1024:.2f} MB\")\n",
    "    \n",
    "    # Show some sample data\n",
    "    print(f\"\\nüìä Sample data (first 5 sequences, first 10 tokens):\")\n",
    "    print(batch[:5, :10])\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 5. Mini Benchmark\n",
    "\n",
    "Let's run a small benchmark to measure throughput over 10 seconds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mini_benchmark(loader, duration=10, batch_size=1000):\n",
    "    \"\"\"Run a mini benchmark for the specified duration.\"\"\"\n",
    "    print(f\"üèÉ Running mini benchmark for {duration} seconds...\")\n",
    "    \n",
    "    # Get first batch to calculate memory per batch\n",
    "    first_batch = next(iter(loader))\n",
    "    bytes_per_batch = first_batch.numel() * first_batch.element_size()\n",
    "    mb_per_batch = bytes_per_batch / (1024 * 1024)\n",
    "    \n",
    "    print(f\"   Batch size: {batch_size} samples\")\n",
    "    print(f\"   Memory per batch: {mb_per_batch:.2f} MB\")\n",
    "    print(f\"   Starting benchmark...\\n\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    batch_count = 0\n",
    "    total_bytes = 0\n",
    "    batch_times = []\n",
    "    \n",
    "    try:\n",
    "        while time.time() - start_time < duration:\n",
    "            batch_start = time.time()\n",
    "            batch = next(iter(loader))\n",
    "            batch_time = time.time() - batch_start\n",
    "            \n",
    "            batch_count += 1\n",
    "            total_bytes += bytes_per_batch\n",
    "            batch_times.append(batch_time * 1000)  # Convert to ms\n",
    "            \n",
    "            # Print progress every few batches\n",
    "            if batch_count % 3 == 0:\n",
    "                elapsed = time.time() - start_time\n",
    "                current_mb_s = (total_bytes / (1024 * 1024)) / elapsed\n",
    "                print(f\"   Batch {batch_count}: {batch_time*1000:.1f}ms, Running avg: {current_mb_s:.1f} MB/s\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è  Benchmark interrupted: {e}\")\n",
    "    \n",
    "    # Calculate final results\n",
    "    total_time = time.time() - start_time\n",
    "    total_mb = total_bytes / (1024 * 1024)\n",
    "    mb_per_second = total_mb / total_time\n",
    "    samples_per_second = (batch_count * batch_size) / total_time\n",
    "    avg_batch_time = np.mean(batch_times)\n",
    "    \n",
    "    return {\n",
    "        'duration': total_time,\n",
    "        'batches': batch_count,\n",
    "        'total_samples': batch_count * batch_size,\n",
    "        'total_mb': total_mb,\n",
    "        'mb_per_second': mb_per_second,\n",
    "        'samples_per_second': samples_per_second,\n",
    "        'avg_batch_time_ms': avg_batch_time,\n",
    "        'batch_times': batch_times\n",
    "    }\n",
    "\n",
    "# Run the benchmark\n",
    "results = run_mini_benchmark(loader, duration=10, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 6. Benchmark Results & Visualization\n",
    "\n",
    "Let's visualize the benchmark results.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}