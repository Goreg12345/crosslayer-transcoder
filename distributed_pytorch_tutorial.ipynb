{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Distributed PyTorch Tutorial\n",
        "\n",
        "This tutorial covers the lower-level distributed PyTorch APIs, including:\n",
        "- `torch.distributed` basics\n",
        "- Process groups and initialization  \n",
        "- Collective operations (AllReduce, Broadcast, etc.)\n",
        "- Distributed Data Parallel (DDP)\n",
        "- Custom distributed training loops\n",
        "\n",
        "## Prerequisites\n",
        "- PyTorch with CUDA support\n",
        "- Multiple GPUs (or multiple processes for CPU-only)\n",
        "- Basic understanding of PyTorch tensors and models\n",
        "\n",
        "## How to Run This Notebook\n",
        "```bash\n",
        "# For 2 GPUs\n",
        "torchrun --nproc_per_node=2 distributed_pytorch_tutorial.ipynb\n",
        "\n",
        "# For 4 GPUs  \n",
        "torchrun --nproc_per_node=4 distributed_pytorch_tutorial.ipynb\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. Basic Distributed Setup\n",
        "\n",
        "First, let's understand the key concepts and environment variables.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA available: True\n",
            "CUDA device count: 4\n",
            "RANK: Not set\n",
            "LOCAL_RANK: Not set\n",
            "WORLD_SIZE: Not set\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.distributed as dist\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn.parallel import DistributedDataParallel as DDP\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "print(f\"CUDA device count: {torch.cuda.device_count()}\")\n",
        "\n",
        "# Check environment variables\n",
        "env_vars = ['RANK', 'LOCAL_RANK', 'WORLD_SIZE']\n",
        "for var in env_vars:\n",
        "    print(f\"{var}: {os.environ.get(var, 'Not set')}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. Process Group Initialization\n",
        "\n",
        "The foundation of distributed PyTorch is the process group.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Process 0/1 (local rank: 0)\n",
            "Distributed initialized: False\n"
          ]
        }
      ],
      "source": [
        "def setup_distributed():\n",
        "    \"\"\"Initialize distributed training\"\"\"\n",
        "    rank = int(os.environ.get('RANK', 0))\n",
        "    local_rank = int(os.environ.get('LOCAL_RANK', 0))\n",
        "    world_size = int(os.environ.get('WORLD_SIZE', 1))\n",
        "    \n",
        "    if world_size > 1:\n",
        "        dist.init_process_group(\n",
        "            backend='nccl',  # Use NCCL for GPU, 'gloo' for CPU\n",
        "            init_method='env://',\n",
        "            world_size=world_size,\n",
        "            rank=rank\n",
        "        )\n",
        "        \n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.set_device(local_rank)\n",
        "    \n",
        "    return rank, local_rank, world_size\n",
        "\n",
        "# Initialize distributed\n",
        "rank, local_rank, world_size = setup_distributed()\n",
        "print(f\"Process {rank}/{world_size} (local rank: {local_rank})\")\n",
        "print(f\"Distributed initialized: {dist.is_initialized()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3. Collective Operations\n",
        "\n",
        "Collective operations are the building blocks of distributed training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distributed not initialized, skipping collectives\n"
          ]
        }
      ],
      "source": [
        "def demonstrate_collectives():\n",
        "    \"\"\"Demonstrate various collective operations\"\"\"\n",
        "    if not dist.is_initialized():\n",
        "        print(\"Distributed not initialized, skipping collectives\")\n",
        "        return\n",
        "    \n",
        "    device = torch.cuda.current_device() if torch.cuda.is_available() else 'cpu'\n",
        "    \n",
        "    # Create a tensor on each process\n",
        "    tensor = torch.tensor([rank + 1], device=device, dtype=torch.float32)\n",
        "    print(f\"Process {rank}: Initial tensor = {tensor}\")\n",
        "    \n",
        "    # 1. AllReduce - Sum all tensors and distribute result to all processes\n",
        "    allreduce_tensor = tensor.clone()\n",
        "    dist.all_reduce(allreduce_tensor, op=dist.ReduceOp.SUM)\n",
        "    print(f\"Process {rank}: After AllReduce = {allreduce_tensor}\")\n",
        "    \n",
        "    # 2. Broadcast - Send tensor from root to all processes\n",
        "    broadcast_tensor = torch.zeros_like(tensor)\n",
        "    if rank == 0:\n",
        "        broadcast_tensor = tensor.clone()\n",
        "    dist.broadcast(broadcast_tensor, src=0)\n",
        "    print(f\"Process {rank}: After Broadcast = {broadcast_tensor}\")\n",
        "\n",
        "demonstrate_collectives()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 4. AllReduce Performance Benchmark\n",
        "\n",
        "Let's benchmark AllReduce performance with different tensor sizes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def benchmark_allreduce():\n",
        "    \"\"\"Benchmark AllReduce performance\"\"\"\n",
        "    if not dist.is_initialized():\n",
        "        print(\"Distributed not initialized, skipping benchmark\")\n",
        "        return\n",
        "    \n",
        "    device = torch.cuda.current_device() if torch.cuda.is_available() else 'cpu'\n",
        "    sizes_mb = [1, 10, 100, 500]\n",
        "    \n",
        "    if rank == 0:\n",
        "        print(f\"\\\\nAllReduce Benchmark (World Size: {world_size})\")\n",
        "        print(\"Size (MB) | Time (ms) | Bandwidth (GB/s)\")\n",
        "        print(\"-\" * 40)\n",
        "    \n",
        "    for size_mb in sizes_mb:\n",
        "        elements = int(size_mb * 1024 * 1024 / 4)  # float32 = 4 bytes\n",
        "        tensor = torch.randn(elements, device=device, dtype=torch.float32)\n",
        "        \n",
        "        # Warmup\n",
        "        for _ in range(3):\n",
        "            test_tensor = tensor.clone()\n",
        "            dist.all_reduce(test_tensor, op=dist.ReduceOp.SUM)\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.synchronize()\n",
        "        \n",
        "        # Benchmark\n",
        "        times = []\n",
        "        for _ in range(10):\n",
        "            test_tensor = tensor.clone()\n",
        "            \n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.synchronize()\n",
        "            start = time.perf_counter()\n",
        "            \n",
        "            dist.all_reduce(test_tensor, op=dist.ReduceOp.SUM)\n",
        "            \n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.synchronize()\n",
        "            end = time.perf_counter()\n",
        "            \n",
        "            times.append(end - start)\n",
        "        \n",
        "        avg_time = np.mean(times)\n",
        "        bandwidth = (size_mb / 1024) / avg_time  # GB/s\n",
        "        \n",
        "        if rank == 0:\n",
        "            print(f\"{size_mb:8d} | {avg_time*1000:8.1f} | {bandwidth:12.1f}\")\n",
        "\n",
        "benchmark_allreduce()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 5. Distributed Data Parallel (DDP)\n",
        "\n",
        "DDP automates the gradient synchronization process.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SimpleModel(nn.Module):\n",
        "    \"\"\"A simple model for demonstration\"\"\"\n",
        "    def __init__(self, input_size=1000, hidden_size=500, output_size=10):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "def ddp_training():\n",
        "    \"\"\"Distributed training using DDP\"\"\"\n",
        "    if not dist.is_initialized():\n",
        "        print(\"Distributed not initialized, skipping DDP training\")\n",
        "        return\n",
        "    \n",
        "    device = torch.cuda.current_device() if torch.cuda.is_available() else 'cpu'\n",
        "    \n",
        "    # Create model and wrap with DDP\n",
        "    model = SimpleModel().to(device)\n",
        "    model = DDP(model, device_ids=[device] if torch.cuda.is_available() else None)\n",
        "    \n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    \n",
        "    # Create dummy data\n",
        "    batch_size = 32\n",
        "    x = torch.randn(batch_size, 1000, device=device)\n",
        "    y = torch.randint(0, 10, (batch_size,), device=device)\n",
        "    \n",
        "    if rank == 0:\n",
        "        print(f\"\\\\nDDP Training (World Size: {world_size})\")\n",
        "        print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "    \n",
        "    # Training loop\n",
        "    for epoch in range(3):\n",
        "        optimizer.zero_grad()\n",
        "        output = model(x)\n",
        "        loss = criterion(output, y)\n",
        "        loss.backward()\n",
        "        \n",
        "        # DDP automatically handles gradient synchronization!\n",
        "        optimizer.step()\n",
        "        \n",
        "        if rank == 0:\n",
        "            print(f\"Epoch {epoch}: Loss = {loss.item():.4f}\")\n",
        "\n",
        "ddp_training()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 6. Manual vs DDP Comparison\n",
        "\n",
        "Let's compare manual gradient synchronization with DDP.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def manual_distributed_training():\n",
        "    \"\"\"Manual distributed training without DDP\"\"\"\n",
        "    if not dist.is_initialized():\n",
        "        print(\"Distributed not initialized, skipping training\")\n",
        "        return\n",
        "    \n",
        "    device = torch.cuda.current_device() if torch.cuda.is_available() else 'cpu'\n",
        "    \n",
        "    # Create model and move to device\n",
        "    model = SimpleModel().to(device)\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    \n",
        "    # Create dummy data\n",
        "    batch_size = 32\n",
        "    x = torch.randn(batch_size, 1000, device=device)\n",
        "    y = torch.randint(0, 10, (batch_size,), device=device)\n",
        "    \n",
        "    if rank == 0:\n",
        "        print(f\"\\\\nManual Distributed Training (World Size: {world_size})\")\n",
        "    \n",
        "    for epoch in range(3):\n",
        "        # Forward pass\n",
        "        optimizer.zero_grad()\n",
        "        output = model(x)\n",
        "        loss = criterion(output, y)\n",
        "        \n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        \n",
        "        # Manual gradient synchronization\n",
        "        for param in model.parameters():\n",
        "            if param.grad is not None:\n",
        "                dist.all_reduce(param.grad, op=dist.ReduceOp.SUM)\n",
        "                param.grad /= world_size  # Average gradients\n",
        "        \n",
        "        # Update parameters\n",
        "        optimizer.step()\n",
        "        \n",
        "        if rank == 0:\n",
        "            print(f\"Epoch {epoch}: Loss = {loss.item():.4f}\")\n",
        "\n",
        "manual_distributed_training()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 7. Cleanup\n",
        "\n",
        "Always clean up distributed resources when done.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def cleanup():\n",
        "    \"\"\"Clean up distributed resources\"\"\"\n",
        "    if dist.is_initialized():\n",
        "        dist.destroy_process_group()\n",
        "        print(f\"Process {rank}: Distributed resources cleaned up\")\n",
        "\n",
        "cleanup()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Key Takeaways\n",
        "\n",
        "1. **Process Groups**: The foundation of distributed PyTorch\n",
        "2. **Collective Operations**: AllReduce, Broadcast, Gather, Scatter\n",
        "3. **DDP**: Automates gradient synchronization with optimizations\n",
        "4. **Manual Control**: Sometimes needed for custom communication patterns\n",
        "5. **Performance**: DDP is usually faster than manual synchronization\n",
        "\n",
        "## Running This Notebook\n",
        "\n",
        "To run this notebook in a distributed setting:\n",
        "\n",
        "```bash\n",
        "# For 2 GPUs\n",
        "torchrun --nproc_per_node=2 distributed_pytorch_tutorial.ipynb\n",
        "\n",
        "# For 4 GPUs\n",
        "torchrun --nproc_per_node=4 distributed_pytorch_tutorial.ipynb\n",
        "\n",
        "# For multi-node (example)\n",
        "torchrun --nproc_per_node=4 --nnodes=2 --node_rank=0 --master_addr=192.168.1.100 --master_port=29500 distributed_pytorch_tutorial.ipynb\n",
        "```\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "- Explore gradient bucketing and overlap strategies\n",
        "- Learn about custom communication patterns  \n",
        "- Understand multi-node training\n",
        "- Study NCCL backend optimizations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hi\n"
          ]
        }
      ],
      "source": [
        "print('hi')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
