{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26710f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Number of GPUs: 1\n",
      "GPU 0: Tesla V100-PCIE-32GB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# select cuda 0\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(\"CUDA available:\", cuda_available)\n",
    "\n",
    "if cuda_available:\n",
    "    # Number of GPUs\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(\"Number of GPUs:\", num_gpus)\n",
    "\n",
    "    # List each deviceâ€™s name\n",
    "    for i in range(num_gpus):\n",
    "        name = torch.cuda.get_device_name(i)\n",
    "        print(f\"GPU {i}: {name}\")\n",
    "else:\n",
    "    print(\"No CUDA devices found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17b618c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from buffer import DiscBuffer\n",
    "\n",
    "buffer = DiscBuffer('/var/local/glang/activations/clt-activations.h5', 'tensor')\n",
    "\n",
    "loader = torch.utils.data.DataLoader(\n",
    "    buffer,\n",
    "    num_workers=20,\n",
    "    prefetch_factor=10,\n",
    "    batch_size=1000,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9d69a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/local/glang/.cache/pypoetry/virtualenvs/crosslayer-transcoder-5Jm3OZ38-py3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/var/local/glang/.cache/pypoetry/virtualenvs/crosslayer-transcoder-5Jm3OZ38-py3.12/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py:73: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgeorglange\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20250521_094128-8dozjd2n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/georglange/wandb_clt/runs/8dozjd2n' target=\"_blank\">solar-sun-1</a></strong> to <a href='https://wandb.ai/georglange/wandb_clt' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/georglange/wandb_clt' target=\"_blank\">https://wandb.ai/georglange/wandb_clt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/georglange/wandb_clt/runs/8dozjd2n' target=\"_blank\">https://wandb.ai/georglange/wandb_clt/runs/8dozjd2n</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name         | Type | Params | Mode \n",
      "----------------------------------------------\n",
      "0 | relu         | ReLU | 0      | train\n",
      "  | other params | n/a  | 1.1 B  | n/a  \n",
      "----------------------------------------------\n",
      "1.1 B     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 B     Total params\n",
      "4,417.044 Total estimated model params size (MB)\n",
      "1         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 1/1000 [00:01<20:31,  0.81it/s, v_num=jd2n]"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 3.80 GiB. GPU 0 has a total capacity of 31.73 GiB of which 1.43 GiB is free. Process 696477 has 384.00 MiB memory in use. Process 712675 has 384.00 MiB memory in use. Including non-PyTorch memory, this process has 29.54 GiB memory in use. Of the allocated memory 25.16 GiB is allocated by PyTorch, and 4.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m logger = WandbLogger(project=\u001b[33m'\u001b[39m\u001b[33mwandb_clt\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      7\u001b[39m trainer = L.Trainer(logger=logger, limit_train_batches=\u001b[32m100000\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCrossLayerTranscoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43md_acts\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m768\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43md_features\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m768\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m12\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn_layers\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m12\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbandwidth\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1.\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlambda\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.0002\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mc\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mjump_thresh\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.03\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1e-3\u001b[39;49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/crosslayer-transcoder-5Jm3OZ38-py3.12/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py:561\u001b[39m, in \u001b[36mTrainer.fit\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    559\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    560\u001b[39m \u001b[38;5;28mself\u001b[39m.should_stop = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m561\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/crosslayer-transcoder-5Jm3OZ38-py3.12/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py:48\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     46\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m trainer.strategy.launcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     47\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[32m     51\u001b[39m     _call_teardown_hook(trainer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/crosslayer-transcoder-5Jm3OZ38-py3.12/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py:599\u001b[39m, in \u001b[36mTrainer._fit_impl\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    592\u001b[39m     download_model_from_registry(ckpt_path, \u001b[38;5;28mself\u001b[39m)\n\u001b[32m    593\u001b[39m ckpt_path = \u001b[38;5;28mself\u001b[39m._checkpoint_connector._select_ckpt_path(\n\u001b[32m    594\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.fn,\n\u001b[32m    595\u001b[39m     ckpt_path,\n\u001b[32m    596\u001b[39m     model_provided=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    597\u001b[39m     model_connected=\u001b[38;5;28mself\u001b[39m.lightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    598\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.stopped\n\u001b[32m    602\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/crosslayer-transcoder-5Jm3OZ38-py3.12/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py:1012\u001b[39m, in \u001b[36mTrainer._run\u001b[39m\u001b[34m(self, model, ckpt_path)\u001b[39m\n\u001b[32m   1007\u001b[39m \u001b[38;5;28mself\u001b[39m._signal_connector.register_signal_handlers()\n\u001b[32m   1009\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1010\u001b[39m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[32m   1011\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1012\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1015\u001b[39m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[32m   1016\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1017\u001b[39m log.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: trainer tearing down\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/crosslayer-transcoder-5Jm3OZ38-py3.12/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py:1056\u001b[39m, in \u001b[36mTrainer._run_stage\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1054\u001b[39m         \u001b[38;5;28mself\u001b[39m._run_sanity_check()\n\u001b[32m   1055\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.autograd.set_detect_anomaly(\u001b[38;5;28mself\u001b[39m._detect_anomaly):\n\u001b[32m-> \u001b[39m\u001b[32m1056\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1057\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1058\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnexpected state \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.state\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/crosslayer-transcoder-5Jm3OZ38-py3.12/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:216\u001b[39m, in \u001b[36m_FitLoop.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    215\u001b[39m     \u001b[38;5;28mself\u001b[39m.on_advance_start()\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m     \u001b[38;5;28mself\u001b[39m.on_advance_end()\n\u001b[32m    218\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/crosslayer-transcoder-5Jm3OZ38-py3.12/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:455\u001b[39m, in \u001b[36m_FitLoop.advance\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.trainer.profiler.profile(\u001b[33m\"\u001b[39m\u001b[33mrun_training_epoch\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m455\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mepoch_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/crosslayer-transcoder-5Jm3OZ38-py3.12/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py:150\u001b[39m, in \u001b[36m_TrainingEpochLoop.run\u001b[39m\u001b[34m(self, data_fetcher)\u001b[39m\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.done:\n\u001b[32m    149\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m         \u001b[38;5;28mself\u001b[39m.on_advance_end(data_fetcher)\n\u001b[32m    152\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/crosslayer-transcoder-5Jm3OZ38-py3.12/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py:320\u001b[39m, in \u001b[36m_TrainingEpochLoop.advance\u001b[39m\u001b[34m(self, data_fetcher)\u001b[39m\n\u001b[32m    317\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m trainer.profiler.profile(\u001b[33m\"\u001b[39m\u001b[33mrun_training_batch\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    318\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m trainer.lightning_module.automatic_optimization:\n\u001b[32m    319\u001b[39m         \u001b[38;5;66;03m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m320\u001b[39m         batch_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mautomatic_optimization\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    321\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    322\u001b[39m         batch_output = \u001b[38;5;28mself\u001b[39m.manual_optimization.run(kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/crosslayer-transcoder-5Jm3OZ38-py3.12/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py:192\u001b[39m, in \u001b[36m_AutomaticOptimization.run\u001b[39m\u001b[34m(self, optimizer, batch_idx, kwargs)\u001b[39m\n\u001b[32m    185\u001b[39m         closure()\n\u001b[32m    187\u001b[39m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[32m    188\u001b[39m \u001b[38;5;66;03m# BACKWARD PASS\u001b[39;00m\n\u001b[32m    189\u001b[39m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[32m    190\u001b[39m \u001b[38;5;66;03m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_optimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    194\u001b[39m result = closure.consume_result()\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result.loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/crosslayer-transcoder-5Jm3OZ38-py3.12/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py:270\u001b[39m, in \u001b[36m_AutomaticOptimization._optimizer_step\u001b[39m\u001b[34m(self, batch_idx, train_step_and_backward_closure)\u001b[39m\n\u001b[32m    267\u001b[39m     \u001b[38;5;28mself\u001b[39m.optim_progress.optimizer.step.increment_ready()\n\u001b[32m    269\u001b[39m \u001b[38;5;66;03m# model hook\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moptimizer_step\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcurrent_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    275\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    276\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_step_and_backward_closure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    277\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_accumulate:\n\u001b[32m    280\u001b[39m     \u001b[38;5;28mself\u001b[39m.optim_progress.optimizer.step.increment_completed()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/crosslayer-transcoder-5Jm3OZ38-py3.12/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py:176\u001b[39m, in \u001b[36m_call_lightning_module_hook\u001b[39m\u001b[34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[39m\n\u001b[32m    173\u001b[39m pl_module._current_fx_name = hook_name\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m trainer.profiler.profile(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m     output = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[32m    179\u001b[39m pl_module._current_fx_name = prev_fx_name\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/crosslayer-transcoder-5Jm3OZ38-py3.12/lib/python3.12/site-packages/lightning/pytorch/core/module.py:1302\u001b[39m, in \u001b[36mLightningModule.optimizer_step\u001b[39m\u001b[34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[39m\n\u001b[32m   1271\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimizer_step\u001b[39m(\n\u001b[32m   1272\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1273\u001b[39m     epoch: \u001b[38;5;28mint\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1276\u001b[39m     optimizer_closure: Optional[Callable[[], Any]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1277\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1278\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Override this method to adjust the default way the :class:`~lightning.pytorch.trainer.trainer.Trainer` calls\u001b[39;00m\n\u001b[32m   1279\u001b[39m \u001b[33;03m    the optimizer.\u001b[39;00m\n\u001b[32m   1280\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1300\u001b[39m \n\u001b[32m   1301\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1302\u001b[39m     \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer_closure\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/crosslayer-transcoder-5Jm3OZ38-py3.12/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py:154\u001b[39m, in \u001b[36mLightningOptimizer.step\u001b[39m\u001b[34m(self, closure, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MisconfigurationException(\u001b[33m\"\u001b[39m\u001b[33mWhen `optimizer.step(closure)` is called, the closure should be callable\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m step_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_strategy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[38;5;28mself\u001b[39m._on_after_step()\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m step_output\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/crosslayer-transcoder-5Jm3OZ38-py3.12/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py:239\u001b[39m, in \u001b[36mStrategy.optimizer_step\u001b[39m\u001b[34m(self, optimizer, closure, model, **kwargs)\u001b[39m\n\u001b[32m    237\u001b[39m \u001b[38;5;66;03m# TODO(fabric): remove assertion once strategy's optimizer_step typing is fixed\u001b[39;00m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, pl.LightningModule)\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprecision_plugin\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/crosslayer-transcoder-5Jm3OZ38-py3.12/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py:123\u001b[39m, in \u001b[36mPrecision.optimizer_step\u001b[39m\u001b[34m(self, optimizer, model, closure, **kwargs)\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Hook to run the optimizer step.\"\"\"\u001b[39;00m\n\u001b[32m    122\u001b[39m closure = partial(\u001b[38;5;28mself\u001b[39m._wrap_closure, model, optimizer, closure)\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/crosslayer-transcoder-5Jm3OZ38-py3.12/lib/python3.12/site-packages/torch/optim/optimizer.py:485\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    480\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    481\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    482\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    483\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m485\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    488\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/crosslayer-transcoder-5Jm3OZ38-py3.12/lib/python3.12/site-packages/torch/optim/optimizer.py:79\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     77\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     78\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     81\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/crosslayer-transcoder-5Jm3OZ38-py3.12/lib/python3.12/site-packages/torch/optim/adam.py:225\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    223\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m closure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    224\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.enable_grad():\n\u001b[32m--> \u001b[39m\u001b[32m225\u001b[39m         loss = \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    227\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.param_groups:\n\u001b[32m    228\u001b[39m     params_with_grad: \u001b[38;5;28mlist\u001b[39m[Tensor] = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/crosslayer-transcoder-5Jm3OZ38-py3.12/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py:109\u001b[39m, in \u001b[36mPrecision._wrap_closure\u001b[39m\u001b[34m(self, model, optimizer, closure)\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_wrap_closure\u001b[39m(\n\u001b[32m     97\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     98\u001b[39m     model: \u001b[33m\"\u001b[39m\u001b[33mpl.LightningModule\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     99\u001b[39m     optimizer: Steppable,\n\u001b[32m    100\u001b[39m     closure: Callable[[], Any],\n\u001b[32m    101\u001b[39m ) -> Any:\n\u001b[32m    102\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the ``on_before_optimizer_step``\u001b[39;00m\n\u001b[32m    103\u001b[39m \u001b[33;03m    hook is called.\u001b[39;00m\n\u001b[32m    104\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    107\u001b[39m \n\u001b[32m    108\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m     closure_result = \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    110\u001b[39m     \u001b[38;5;28mself\u001b[39m._after_closure(model, optimizer)\n\u001b[32m    111\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m closure_result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/crosslayer-transcoder-5Jm3OZ38-py3.12/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py:146\u001b[39m, in \u001b[36mClosure.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    144\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> Optional[Tensor]:\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m     \u001b[38;5;28mself\u001b[39m._result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result.loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/crosslayer-transcoder-5Jm3OZ38-py3.12/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/crosslayer-transcoder-5Jm3OZ38-py3.12/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py:140\u001b[39m, in \u001b[36mClosure.closure\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    137\u001b[39m     \u001b[38;5;28mself\u001b[39m._zero_grad_fn()\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m step_output.closure_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_backward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_output\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclosure_loss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m step_output\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/crosslayer-transcoder-5Jm3OZ38-py3.12/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py:241\u001b[39m, in \u001b[36m_AutomaticOptimization._make_backward_fn.<locals>.backward_fn\u001b[39m\u001b[34m(loss)\u001b[39m\n\u001b[32m    240\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbackward_fn\u001b[39m(loss: Tensor) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m     \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbackward\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/crosslayer-transcoder-5Jm3OZ38-py3.12/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py:328\u001b[39m, in \u001b[36m_call_strategy_hook\u001b[39m\u001b[34m(trainer, hook_name, *args, **kwargs)\u001b[39m\n\u001b[32m    325\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m trainer.profiler.profile(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer.strategy.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     output = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[32m    331\u001b[39m pl_module._current_fx_name = prev_fx_name\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/crosslayer-transcoder-5Jm3OZ38-py3.12/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py:213\u001b[39m, in \u001b[36mStrategy.backward\u001b[39m\u001b[34m(self, closure_loss, optimizer, *args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.lightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    211\u001b[39m closure_loss = \u001b[38;5;28mself\u001b[39m.precision_plugin.pre_backward(closure_loss, \u001b[38;5;28mself\u001b[39m.lightning_module)\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprecision_plugin\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlightning_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    215\u001b[39m closure_loss = \u001b[38;5;28mself\u001b[39m.precision_plugin.post_backward(closure_loss, \u001b[38;5;28mself\u001b[39m.lightning_module)\n\u001b[32m    216\u001b[39m \u001b[38;5;28mself\u001b[39m.post_backward(closure_loss)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/crosslayer-transcoder-5Jm3OZ38-py3.12/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py:73\u001b[39m, in \u001b[36mPrecision.backward\u001b[39m\u001b[34m(self, tensor, model, optimizer, *args, **kwargs)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbackward\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[32m     55\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     60\u001b[39m     **kwargs: Any,\n\u001b[32m     61\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     62\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Performs the actual backpropagation.\u001b[39;00m\n\u001b[32m     63\u001b[39m \n\u001b[32m     64\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     71\u001b[39m \n\u001b[32m     72\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/crosslayer-transcoder-5Jm3OZ38-py3.12/lib/python3.12/site-packages/lightning/pytorch/core/module.py:1097\u001b[39m, in \u001b[36mLightningModule.backward\u001b[39m\u001b[34m(self, loss, *args, **kwargs)\u001b[39m\n\u001b[32m   1095\u001b[39m     \u001b[38;5;28mself\u001b[39m._fabric.backward(loss, *args, **kwargs)\n\u001b[32m   1096\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1097\u001b[39m     \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/crosslayer-transcoder-5Jm3OZ38-py3.12/lib/python3.12/site-packages/torch/_tensor.py:648\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    640\u001b[39m         Tensor.backward,\n\u001b[32m    641\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    646\u001b[39m         inputs=inputs,\n\u001b[32m    647\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/crosslayer-transcoder-5Jm3OZ38-py3.12/lib/python3.12/site-packages/torch/autograd/__init__.py:353\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    348\u001b[39m     retain_graph = create_graph\n\u001b[32m    350\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/crosslayer-transcoder-5Jm3OZ38-py3.12/lib/python3.12/site-packages/torch/autograd/graph.py:824\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    823\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    828\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 3.80 GiB. GPU 0 has a total capacity of 31.73 GiB of which 1.43 GiB is free. Process 696477 has 384.00 MiB memory in use. Process 712675 has 384.00 MiB memory in use. Including non-PyTorch memory, this process has 29.54 GiB memory in use. Of the allocated memory 25.16 GiB is allocated by PyTorch, and 4.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from clt import CrossLayerTranscoder\n",
    "import lightning.pytorch as L\n",
    "\n",
    "\n",
    "logger = WandbLogger(project='wandb_clt')\n",
    "trainer = L.Trainer(logger=logger, limit_train_batches=100000)\n",
    "trainer.fit(\n",
    "    model=CrossLayerTranscoder(config={\n",
    "        \"d_acts\": 768,\n",
    "        \"d_features\": 768 * 12,\n",
    "        \"n_layers\": 12,\n",
    "        \"bandwidth\": 1.,\n",
    "        \"lambda\": 0.0002,\n",
    "        \"c\": 0.1,\n",
    "        \"jump_thresh\": 0.03,\n",
    "        \"lr\": 1e-3\n",
    "    }),\n",
    "    train_dataloaders=loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3179d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def K(x):\n",
    "    return H(x + .5) - H(x - .5)\n",
    "\n",
    "def H(x):\n",
    "    return np.where(x > 0, np.ones_like(x), np.zeros_like(x))\n",
    "\n",
    "def derivative(x):\n",
    "    e = .5\n",
    "    theta = .5\n",
    "    return (-1/e) * K((x - theta) / e)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot(x, y):\n",
    "    plt.plot(x, y)\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.title('Plot of y vs x')\n",
    "    plt.grid()\n",
    "    plt.xlim(0, 2)\n",
    "    plt.show()\n",
    "\n",
    "x = np.linspace(-5, 5, 100)\n",
    "y = derivative(x)\n",
    "plot(x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89fb16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(batchsize nlayer dfeature), (nlayer dfeatures dacts) -> (batchsize nlayer dacts)\n",
    "\n",
    "\n",
    "batch tolayer dacts = \n",
    "\n",
    "for n in fromlayer:\n",
    "    for f in dfeatures:\n",
    "        add acts[batch nlayers f] * W_dec[n tolayer f dacts] * mask[fromlayer tolayer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2572abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1., 6., 1., 1., 1., 1., 1.],\n",
       "        [0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.triu(torch.ones(12, 12))\n",
    "t[0, 6] = 6\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6bc2ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[3, 1, 1, 7],\n",
       "         [3, 6, 0, 1],\n",
       "         [5, 7, 6, 2]]),\n",
       " tensor([[7, 2, 3, 1, 0],\n",
       "         [3, 9, 7, 2, 6],\n",
       "         [9, 4, 5, 3, 0],\n",
       "         [8, 6, 3, 9, 8]]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.randint(0, 10, (3, 4))\n",
    "b = torch.randint(0, 10, (4, 5))\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d4d3d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 81,  63,  54,  45,  42],\n",
       "         [ 27,  21,  18,  15,  14],\n",
       "         [ 27,  21,  18,  15,  14],\n",
       "         [189, 147, 126, 105,  98]],\n",
       "\n",
       "        [[ 81,  63,  54,  45,  42],\n",
       "         [162, 126, 108,  90,  84],\n",
       "         [  0,   0,   0,   0,   0],\n",
       "         [ 27,  21,  18,  15,  14]],\n",
       "\n",
       "        [[135, 105,  90,  75,  70],\n",
       "         [189, 147, 126, 105,  98],\n",
       "         [162, 126, 108,  90,  84],\n",
       "         [ 54,  42,  36,  30,  28]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from einops import einsum\n",
    "\n",
    "einsum(a, b, 'a b, c d -> a b d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c8d01a",
   "metadata": {},
   "source": [
    "res[a b d] = \n",
    "    for j in range(c):\n",
    "        add a[a, b] * b[c, d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c8929a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dce36e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tril(torch.ones(12, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319bf381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.1049,  0.6891, -0.2221],\n",
       "          [-0.6869, -1.8075,  1.1821],\n",
       "          [ 1.9893, -0.8786,  1.2487],\n",
       "          [ 0.9046,  0.4721, -0.8072]],\n",
       " \n",
       "         [[ 0.4983,  0.7082,  0.0465],\n",
       "          [ 0.3724,  0.8592, -0.3992],\n",
       "          [-0.5043,  0.9919, -1.5528],\n",
       "          [-1.2314, -0.1028,  0.0340]]]),\n",
       " tensor([[2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2.]]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make two small example tensors\n",
    "x = torch.randn(2, 4, 3)\n",
    "y = torch.ones(3, 4) * 2\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f20fa71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.1438,  1.1438,  1.1438,  1.1438],\n",
       "         [-2.6246, -2.6246, -2.6246, -2.6246],\n",
       "         [ 4.7188,  4.7188,  4.7188,  4.7188],\n",
       "         [ 1.1390,  1.1390,  1.1390,  1.1390]],\n",
       "\n",
       "        [[ 2.5060,  2.5060,  2.5060,  2.5060],\n",
       "         [ 1.6648,  1.6648,  1.6648,  1.6648],\n",
       "         [-2.1303, -2.1303, -2.1303, -2.1303],\n",
       "         [-2.6004, -2.6004, -2.6004, -2.6004]]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x @ y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df3345d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.1438,  1.1438,  1.1438,  1.1438],\n",
       "         [-2.6246, -2.6246, -2.6246, -2.6246],\n",
       "         [ 4.7188,  4.7188,  4.7188,  4.7188],\n",
       "         [ 1.1390,  1.1390,  1.1390,  1.1390]],\n",
       "\n",
       "        [[ 2.5060,  2.5060,  2.5060,  2.5060],\n",
       "         [ 1.6648,  1.6648,  1.6648,  1.6648],\n",
       "         [-2.1303, -2.1303, -2.1303, -2.1303],\n",
       "         [-2.6004, -2.6004, -2.6004, -2.6004]]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e899db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.1438,  1.1438,  1.1438,  1.1438],\n",
       "         [-2.6246, -2.6246, -2.6246, -2.6246],\n",
       "         [ 4.7188,  4.7188,  4.7188,  4.7188],\n",
       "         [ 1.1390,  1.1390,  1.1390,  1.1390]],\n",
       "\n",
       "        [[ 2.5060,  2.5060,  2.5060,  2.5060],\n",
       "         [ 1.6648,  1.6648,  1.6648,  1.6648],\n",
       "         [-2.1303, -2.1303, -2.1303, -2.1303],\n",
       "         [-2.6004, -2.6004, -2.6004, -2.6004]]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from einops import einsum\n",
    "\n",
    "einsum(x, y, 'a b c, c d -> a b d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b93fb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crosslayer-transcoder-5Jm3OZ38-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
