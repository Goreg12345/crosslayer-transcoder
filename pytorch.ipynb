{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd2eeddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b1b7e554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3.],\n",
       "         [4., 5., 6.]]),\n",
       " tensor([[1., 1., 1.],\n",
       "         [1., 1., 1.]]),\n",
       " tensor([[0.1619, 0.0282, 0.7678],\n",
       "         [0.6931, 0.2147, 0.3768]]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float32)\n",
    "t2 = torch.ones((2, 3))\n",
    "t3 = torch.rand((2, 3))\n",
    "t1, t2, t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6b5ccd39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 2.0000, 3.0000],\n",
       "        [4.0000, 5.0000, 6.0000],\n",
       "        [1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000],\n",
       "        [0.2993, 0.6715, 0.1830],\n",
       "        [0.5794, 0.2616, 0.4787]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([t1, t2, t3], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2c7ef0f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000, 1.0000, 0.2993],\n",
       "         [2.0000, 1.0000, 0.6715],\n",
       "         [3.0000, 1.0000, 0.1830]],\n",
       "\n",
       "        [[4.0000, 1.0000, 0.5794],\n",
       "         [5.0000, 1.0000, 0.2616],\n",
       "         [6.0000, 1.0000, 0.4787]]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([t1, t2, t3], dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "777b022b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.,  6.],\n",
       "        [15., 15.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 @ t2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9c36cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum('ij,kj->ik', t1, t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6d63c325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2a93a848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "61547868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[36., 36.],\n",
       "        [90., 90.]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1 = torch.einsum('ij,kj->ik', t1, t2)\n",
    "r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ef1c669e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((<BmmBackward0 at 0x7f27a20ef3d0>, 0),)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1.grad_fn.next_functions[0][0].next_functions[0][0].next_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0d6118df",
   "metadata": {},
   "outputs": [],
   "source": [
    "r1.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "520b0c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.]],\n",
       " \n",
       "         [[1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.]]]),\n",
       " tensor([0, 1, 2, 3]))"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1 = torch.ones((2, 3, 4), dtype=torch.float32)\n",
    "b2 = torch.arange(4)\n",
    "b1, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5c14e134",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2) must match the size of tensor b (4) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[122]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mb1\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mb2\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: The size of tensor a (2) must match the size of tensor b (4) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "b1 + b2[:, None, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "0c1b48aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]], device='cuda:3')"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1.to('cuda:3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "2244d0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start alloc: 25.29792 MB\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: setup\n",
    "import torch, gc, inspect, psutil, os\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_peak_memory_stats(device)\n",
    "print(\"Start alloc:\", torch.cuda.memory_allocated(device) / 1e6, \"MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "cb485957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After loop: 16799.344128 MB\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: deliberate leak\n",
    "losses = []                    # bad: grows every iteration\n",
    "for _ in range(2000):\n",
    "    x = torch.randn(1024, 1024, device=device, requires_grad=True)\n",
    "    y = torch.randn(1024, 1024, device=device)\n",
    "    loss = (x @ y).mean()\n",
    "    losses.append(loss)        # leak happens here\n",
    "print(\"After loop:\", torch.cuda.max_memory_allocated(device) / 1e6, \"MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "657c77db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: ['W', 'W2', 'linear.weight', 'linear.bias']\n",
      "Buffers: ['running_sum']\n"
     ]
    }
   ],
   "source": [
    "import torch, torch.nn as nn\n",
    "\n",
    "class TinyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(4, 4, bias=True)          # parameter auto-registered\n",
    "        self.W = nn.Parameter(torch.ones((4, 4)))  # parameter\n",
    "        self.register_parameter(\"W2\", nn.Parameter(torch.ones((4, 4))))  # parameter\n",
    "        self.register_buffer(\"running_sum\", torch.zeros(4))  # buffer\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x) + self.running_sum\n",
    "\n",
    "net = TinyNet()\n",
    "print(\"Parameters:\", [n for n, _ in net.named_parameters()])\n",
    "print(\"Buffers:\", [n for n, _ in net.named_buffers()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "07a1e0d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('W',\n",
       "              tensor([[1., 1., 1., 1.],\n",
       "                      [1., 1., 1., 1.],\n",
       "                      [1., 1., 1., 1.],\n",
       "                      [1., 1., 1., 1.]])),\n",
       "             ('W2',\n",
       "              tensor([[1., 1., 1., 1.],\n",
       "                      [1., 1., 1., 1.],\n",
       "                      [1., 1., 1., 1.],\n",
       "                      [1., 1., 1., 1.]])),\n",
       "             ('running_sum', tensor([0., 0., 0., 0.])),\n",
       "             ('linear.weight',\n",
       "              tensor([[-0.4288, -0.2519, -0.1056,  0.3239],\n",
       "                      [ 0.1157, -0.0893,  0.1409, -0.1096],\n",
       "                      [ 0.1950,  0.3643,  0.0233,  0.2756],\n",
       "                      [ 0.4444, -0.2664, -0.0512,  0.2670]])),\n",
       "             ('linear.bias', tensor([ 0.4106, -0.4493, -0.2060,  0.3858]))])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "a2e5a4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: a leaf Variable that requires grad is being used in an in-place operation.\n"
     ]
    }
   ],
   "source": [
    "class BadReLU(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return torch.relu_(x)      # in-place\n",
    "\n",
    "bad = BadReLU()\n",
    "t = torch.randn(3, requires_grad=True)\n",
    "try:\n",
    "    bad(t).sum().backward()\n",
    "except RuntimeError as e:\n",
    "    print(\"Error:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75da9f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04833f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffd7822",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04db8484",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67d9380",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crosslayer-transcoder-5Jm3OZ38-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
