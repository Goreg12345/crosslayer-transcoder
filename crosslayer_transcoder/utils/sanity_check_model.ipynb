{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e36e2f4",
   "metadata": {},
   "source": [
    "# Sanity check model\n",
    "\n",
    "Sanity check the model checkpoint by loading it into our own arch and then running a prompt through the encoder to see what the sparsity of the model is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de7531d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30928294793d45d7b42fe9bb296d4278",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1217 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1561 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1174 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2459 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2027 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JumpReLUCrossLayerTranscoderModule(\n",
      "  (model): CrossLayerTranscoder(\n",
      "    (encoder): Encoder()\n",
      "    (decoder): CrosslayerDecoder()\n",
      "    (nonlinearity): JumpReLU()\n",
      "    (input_standardizer): DimensionwiseInputStandardizer()\n",
      "    (output_standardizer): DimensionwiseOutputStandardizer()\n",
      "  )\n",
      "  (replacement_model): ReplacementModelAccuracy(\n",
      "    (replacement_model): ReplacementModel()\n",
      "  )\n",
      "  (dead_features): DeadFeatures()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from crosslayer_transcoder.utils.module_builder import build_module_from_config, yaml_to_config\n",
    "from crosslayer_transcoder.utils.checkpoints import load_model_from_lightning_checkpoint\n",
    "\n",
    "config_path = \"../../config/circuit-tracer.yaml\"\n",
    "checkpoint_path = \"../checkpoints/clt.ckpt\"\n",
    "\n",
    "config = yaml_to_config(config_path)\n",
    "clt_module = build_module_from_config(config)\n",
    "\n",
    "clt_module = load_model_from_lightning_checkpoint(clt_module, checkpoint_path)\n",
    "\n",
    "print(clt_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5030984",
   "metadata": {},
   "source": [
    "## Collect Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "597a9d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnsight import LanguageModel\n",
    "prompt = (\n",
    "    \"The capital of state containing Dallas is\"  # What you want to get the graph for\n",
    ")\n",
    "llm = LanguageModel(\"openai-community/gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cda0fb9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 7, 768])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "mlp_in_activations = []\n",
    "\n",
    "with llm.trace(prompt) as trace:\n",
    "    for layer in range(12):\n",
    "        layer_activations = llm.transformer.h[layer].ln_2.input.save()\n",
    "        mlp_in_activations.append(layer_activations.squeeze(0))\n",
    "\n",
    "mlp_in_activations = torch.stack(mlp_in_activations, dim=0)\n",
    "\n",
    "print(mlp_in_activations.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57664d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 12, 768])\n"
     ]
    }
   ],
   "source": [
    "import einops\n",
    "\n",
    "in_acts = einops.rearrange(mlp_in_activations, \"l b d -> b l d\")\n",
    "print(in_acts.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3dd5db",
   "metadata": {},
   "source": [
    "## Encode w/o standarizer folding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8458d4d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e5b2b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 12, 10000])\n",
      "sparse_features._nnz(): 70298\n",
      "l0_avg_per_layer: 836.8809814453125\n"
     ]
    }
   ],
   "source": [
    "features = clt_module.model.encode(in_acts)\n",
    "\n",
    "print(features.shape)\n",
    "\n",
    "sparse_features = features.to_sparse()\n",
    "print(f\"sparse_features._nnz(): {sparse_features._nnz()}\")\n",
    "\n",
    "l0_avg_per_layer = torch.count_nonzero(features > 0) / (\n",
    "    features.shape[0] * features.shape[1]\n",
    ")\n",
    "print(f\"l0_avg_per_layer: {l0_avg_per_layer.item()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d847db4",
   "metadata": {},
   "source": [
    "## Encode w/ folding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26589596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 12, 10000])\n",
      "sparse_features._nnz(): 17896\n",
      "l0_avg_per_layer: 213.04762268066406\n"
     ]
    }
   ],
   "source": [
    "\n",
    "features = clt_module.model.encode_with_standardizer_folding(in_acts)\n",
    "\n",
    "print(features.shape)\n",
    "\n",
    "sparse_features = features.to_sparse()\n",
    "print(f\"sparse_features._nnz(): {sparse_features._nnz()}\")\n",
    "\n",
    "l0_avg_per_layer = torch.count_nonzero(features > 0) / (features.shape[0] * features.shape[1])\n",
    "print(f\"l0_avg_per_layer: {l0_avg_per_layer.item()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130f0259",
   "metadata": {},
   "source": [
    "## Run encoding in bfloat16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "753de1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 12, 10000])\n",
      "sparse_features._nnz(): 17843\n",
      "l0_avg_per_layer: 212.4166717529297\n"
     ]
    }
   ],
   "source": [
    "in_acts = in_acts.to(torch.bfloat16)\n",
    "clt_module.model.to(torch.bfloat16)\n",
    "features = clt_module.model.encode_with_standardizer_folding(in_acts)\n",
    "\n",
    "print(features.shape)\n",
    "\n",
    "sparse_features = features.to_sparse()\n",
    "print(f\"sparse_features._nnz(): {sparse_features._nnz()}\")\n",
    "\n",
    "l0_avg_per_layer = torch.count_nonzero(features > 0) / (\n",
    "    features.shape[0] * features.shape[1]\n",
    ")\n",
    "print(f\"l0_avg_per_layer: {l0_avg_per_layer.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f90530",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
