{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e36e2f4",
   "metadata": {},
   "source": [
    "# Model Sanity checks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cecc0fd",
   "metadata": {},
   "source": [
    "## Load into `crosslayer-transcoder` arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7531d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ade35ae315f8420ebf9281b299159eda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1217 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1561 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1174 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2459 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2027 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JumpReLUCrossLayerTranscoderModule(\n",
      "  (model): CrossLayerTranscoder(\n",
      "    (encoder): Encoder()\n",
      "    (decoder): CrosslayerDecoder()\n",
      "    (nonlinearity): JumpReLU()\n",
      "    (input_standardizer): DimensionwiseInputStandardizer()\n",
      "    (output_standardizer): DimensionwiseOutputStandardizer()\n",
      "  )\n",
      "  (replacement_model): ReplacementModelAccuracy(\n",
      "    (replacement_model): ReplacementModel()\n",
      "  )\n",
      "  (dead_features): DeadFeatures()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from crosslayer_transcoder.utils.module_builder import build_module_from_config \n",
    "import torch\n",
    "\n",
    "config_path = \"../../config/circuit-tracer.yaml\"\n",
    "checkpoint_path = \"../checkpoints/clt.ckpt\"\n",
    "\n",
    "with open(config_path, \"r\") as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    clt_module = build_module_from_config(config[\"model\"])\n",
    "\n",
    "checkpoint = torch.load(checkpoint_path, map_location='cuda:0')\n",
    "clt_module.load_state_dict(checkpoint[\"state_dict\"])\n",
    "\n",
    "print(clt_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5030984",
   "metadata": {},
   "source": [
    "### Collect Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "597a9d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnsight import LanguageModel\n",
    "prompt = (\n",
    "    \"The capital of state containing Dallas is\"  # What you want to get the graph for\n",
    ")\n",
    "llm = LanguageModel(\"openai-community/gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cda0fb9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 7, 768])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "mlp_in_activations = []\n",
    "\n",
    "with llm.trace(prompt) as trace:\n",
    "    for layer in range(12):\n",
    "        layer_activations = llm.transformer.h[layer].ln_2.input.save()\n",
    "        mlp_in_activations.append(layer_activations.squeeze(0))\n",
    "\n",
    "mlp_in_activations = torch.stack(mlp_in_activations, dim=0)\n",
    "\n",
    "print(mlp_in_activations.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57664d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 12, 768])\n"
     ]
    }
   ],
   "source": [
    "import einops\n",
    "\n",
    "in_acts = einops.rearrange(mlp_in_activations, \"l b d -> b l d\")\n",
    "print(in_acts.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3dd5db",
   "metadata": {},
   "source": [
    "### Encode w/o standarizer folding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8458d4d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e5b2b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 12, 10000])\n",
      "sparse_features._nnz(): 70298\n",
      "l0_avg_per_layer: 836.8809814453125\n"
     ]
    }
   ],
   "source": [
    "features = clt_module.model.encode(in_acts)\n",
    "\n",
    "print(features.shape)\n",
    "\n",
    "sparse_features = features.to_sparse()\n",
    "print(f\"sparse_features._nnz(): {sparse_features._nnz()}\")\n",
    "\n",
    "l0_avg_per_layer = torch.count_nonzero(features > 0) / (\n",
    "    features.shape[0] * features.shape[1]\n",
    ")\n",
    "print(f\"l0_avg_per_layer: {l0_avg_per_layer.item()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d847db4",
   "metadata": {},
   "source": [
    "### Encode w/ folding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26589596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 12, 10000])\n",
      "sparse_features._nnz(): 17896\n",
      "l0_avg_per_layer: 213.04762268066406\n"
     ]
    }
   ],
   "source": [
    "\n",
    "features = clt_module.model.encode_with_standardizer_folding(in_acts)\n",
    "\n",
    "print(features.shape)\n",
    "\n",
    "sparse_features = features.to_sparse()\n",
    "print(f\"sparse_features._nnz(): {sparse_features._nnz()}\")\n",
    "\n",
    "l0_avg_per_layer = torch.count_nonzero(features > 0) / (features.shape[0] * features.shape[1])\n",
    "print(f\"l0_avg_per_layer: {l0_avg_per_layer.item()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130f0259",
   "metadata": {},
   "source": [
    "### Run encoding in bfloat16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "753de1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 12, 10000])\n",
      "sparse_features._nnz(): 17843\n",
      "l0_avg_per_layer: 212.4166717529297\n"
     ]
    }
   ],
   "source": [
    "in_acts = in_acts.to(torch.bfloat16)\n",
    "clt_module.model.to(torch.bfloat16)\n",
    "features = clt_module.model.encode_with_standardizer_folding(in_acts)\n",
    "\n",
    "print(features.shape)\n",
    "\n",
    "sparse_features = features.to_sparse()\n",
    "print(f\"sparse_features._nnz(): {sparse_features._nnz()}\")\n",
    "\n",
    "l0_avg_per_layer = torch.count_nonzero(features > 0) / (\n",
    "    features.shape[0] * features.shape[1]\n",
    ")\n",
    "print(f\"l0_avg_per_layer: {l0_avg_per_layer.item()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeca368d",
   "metadata": {},
   "source": [
    "## Interface w circuit tracer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34ce09c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from crosslayer_transcoder.utils.model_converters.circuit_tracer import (\n",
    "    CircuitTracerConverter,\n",
    ")\n",
    "from circuit_tracer.transcoder.cross_layer_transcoder import load_clt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c839fca",
   "metadata": {},
   "source": [
    "### Convert model to circuit-tracer format and save `.safetensors`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c55f63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting CLT : 100%|██████████| 12/12 [00:13<00:00,  1.15s/it]\n"
     ]
    }
   ],
   "source": [
    "save_dir = pathlib.Path(\"clt_module_test\")\n",
    "feature_input_hook = \"hook_resid_mid\"\n",
    "feature_output_hook = \"hook_mlp_out\"\n",
    "\n",
    "converter = CircuitTracerConverter(\n",
    "save_dir=save_dir,\n",
    "feature_input_hook=feature_input_hook,\n",
    "    feature_output_hook=feature_output_hook,\n",
    ")\n",
    "converter.convert_and_save(clt_module, dtype=torch.bfloat16) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9b91b8",
   "metadata": {},
   "source": [
    "### Load CLT into circuit-tracer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb5ad901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "['W_enc_0', 'b_dec_0', 'b_enc_0', 'threshold_0']\n",
      "['W_enc_1', 'b_dec_1', 'b_enc_1', 'threshold_1']\n",
      "['W_enc_2', 'b_dec_2', 'b_enc_2', 'threshold_2']\n",
      "['W_enc_3', 'b_dec_3', 'b_enc_3', 'threshold_3']\n",
      "['W_enc_4', 'b_dec_4', 'b_enc_4', 'threshold_4']\n",
      "['W_enc_5', 'b_dec_5', 'b_enc_5', 'threshold_5']\n",
      "['W_enc_6', 'b_dec_6', 'b_enc_6', 'threshold_6']\n",
      "['W_enc_7', 'b_dec_7', 'b_enc_7', 'threshold_7']\n",
      "['W_enc_8', 'b_dec_8', 'b_enc_8', 'threshold_8']\n",
      "['W_enc_9', 'b_dec_9', 'b_enc_9', 'threshold_9']\n",
      "['W_enc_10', 'b_dec_10', 'b_enc_10', 'threshold_10']\n",
      "['W_enc_11', 'b_dec_11', 'b_enc_11', 'threshold_11']\n",
      "dict_keys(['b_dec', 'b_enc', 'activation_function.threshold', 'W_enc', 'W_dec.0', 'W_dec.1', 'W_dec.2', 'W_dec.3', 'W_dec.4', 'W_dec.5', 'W_dec.6', 'W_dec.7', 'W_dec.8', 'W_dec.9', 'W_dec.10', 'W_dec.11'])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "circuit_tracer_transcoder, state_dict_pre_load = load_clt(\n",
    "    clt_path=save_dir.as_posix(),\n",
    "    lazy_decoder=False,\n",
    "    lazy_encoder=False,\n",
    "    feature_input_hook=feature_input_hook,\n",
    "    feature_output_hook=feature_output_hook,\n",
    "    dtype=torch.bfloat16,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3df8f67",
   "metadata": {},
   "source": [
    "### Sanity checks for loaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78ff27a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import einops\n",
    "from safetensors import safe_open\n",
    "import torch\n",
    "import os\n",
    "# sanity check against original model\n",
    "\n",
    "clt_path = save_dir.as_posix()\n",
    "assert circuit_tracer_transcoder.clt_path == clt_path\n",
    "\n",
    "\n",
    "# TEST: state_dict_pre_load weights match the files before being loaded into the model\n",
    "for i in range(circuit_tracer_transcoder.n_layers):\n",
    "    enc_file = os.path.join(clt_path, f\"W_enc_{i}.safetensors\")\n",
    "    with safe_open(enc_file, framework=\"pt\", device=circuit_tracer_transcoder.device.type) as f:\n",
    "        w_file = f.get_tensor(f\"W_enc_{i}\").to(\n",
    "            dtype=state_dict_pre_load[\"W_enc\"][i].dtype,\n",
    "            device=state_dict_pre_load[\"W_enc\"][i].device,\n",
    "        )\n",
    "        w_state = state_dict_pre_load[\"W_enc\"][i]\n",
    "        assert w_file.shape == w_state.shape, (\n",
    "            f\"W_enc_{i} shape mismatch: {w_file.shape} != {w_state.shape}\"\n",
    "        )\n",
    "        assert w_file.dtype == w_state.dtype, (\n",
    "            f\"W_enc_{i} dtype mismatch: {w_file.dtype} != {w_state.dtype}\"\n",
    "        )\n",
    "        assert torch.allclose(w_file, w_state), (\n",
    "            i,\n",
    "            (w_file - w_state).abs().max().item(),\n",
    "        )\n",
    "\n",
    "\n",
    "# TEST: weights in the files should equal weights from the circuit_tracer_transcoder\n",
    "for i in range(circuit_tracer_transcoder.n_layers):\n",
    "    w_model = circuit_tracer_transcoder._get_encoder_weights(i)  # works for both lazy and eager\n",
    "    enc_file = os.path.join(clt_path, f\"W_enc_{i}.safetensors\")\n",
    "    with safe_open(enc_file, framework=\"pt\", device=circuit_tracer_transcoder.device.type) as f:\n",
    "        w_file = f.get_tensor(f\"W_enc_{i}\").to(\n",
    "            dtype=w_model.dtype, device=w_model.device\n",
    "        )\n",
    "\n",
    "    assert w_model.shape == w_file.shape\n",
    "    assert w_model.dtype == w_file.dtype\n",
    "    assert torch.allclose(w_model, w_file), (i, (w_model - w_file).abs().max().item())\n",
    "\n",
    "\n",
    "# fold\n",
    "standardizer = clt_module.model.input_standardizer\n",
    "W_enc_folded, b_enc_folded = standardizer.fold_in_encoder(\n",
    "    clt_module.model.encoder.W.to(dtype=torch.bfloat16),\n",
    "    clt_module.model.encoder.b.to(dtype=torch.bfloat16),\n",
    ")\n",
    "\n",
    "W_enc_folded = W_enc_folded.to(dtype=torch.bfloat16)\n",
    "b_enc_folded = b_enc_folded.to(dtype=torch.bfloat16)\n",
    "\n",
    "state_dict = {}\n",
    "device = clt_module.device\n",
    "# TEST: eights in the file should equal the folded weights\n",
    "for i in range(clt_module.model.encoder.n_layers):\n",
    "    enc_file = f\"W_enc_{i}.safetensors\"\n",
    "    with safe_open(\n",
    "        os.path.join(clt_path, enc_file), framework=\"pt\", device=device.type\n",
    "    ) as f:\n",
    "        assert W_enc_folded[i].T.shape == f.get_tensor(f\"W_enc_{i}\").shape, (\n",
    "            f\"W_enc_{i} shape mismatch: {W_enc_folded[i].shape} != {f.get_tensor(f'W_enc_{i}').shape}\"\n",
    "        )\n",
    "        assert W_enc_folded[i].dtype == f.get_tensor(f\"W_enc_{i}\").dtype, (\n",
    "            f\"W_enc_{i} dtype mismatch: {W_enc_folded[i].dtype} != {f.get_tensor(f'W_enc_{i}').dtype}\"\n",
    "        )\n",
    "        assert torch.allclose(W_enc_folded[i].T, f.get_tensor(f\"W_enc_{i}\"))\n",
    "        assert torch.allclose(b_enc_folded[i], f.get_tensor(f\"b_enc_{i}\"))\n",
    "\n",
    "        # loaded model\n",
    "        assert circuit_tracer_transcoder.W_enc[i].shape == f.get_tensor(f\"W_enc_{i}\").shape\n",
    "        assert circuit_tracer_transcoder.W_enc[i].dtype == f.get_tensor(f\"W_enc_{i}\").dtype, (\n",
    "            f\"W_enc_{i} dtype mismatch: {circuit_tracer_transcoder.W_enc[i].dtype} != {f.get_tensor(f'W_enc_{i}').dtype}\"\n",
    "        )\n",
    "        assert torch.allclose(\n",
    "            circuit_tracer_transcoder.W_enc[i], f.get_tensor(f\"W_enc_{i}\").to(\"cuda:0\")\n",
    "        )\n",
    "\n",
    "\n",
    "for i in range(clt_module.model.encoder.n_layers):\n",
    "    rearranged_W_enc = einops.rearrange(\n",
    "        W_enc_folded[i],\n",
    "        \"d_acts d_features -> d_features d_acts\",\n",
    "    ).contiguous()\n",
    "    assert torch.allclose(\n",
    "        rearranged_W_enc.to(\"cuda:0\"), circuit_tracer_transcoder.W_enc[i].to(\"cuda:0\")\n",
    "    )\n",
    "    assert torch.allclose(\n",
    "        b_enc_folded[i].to(dtype=torch.bfloat16).to(\"cuda:0\"),\n",
    "        circuit_tracer_transcoder.b_enc[i].to(dtype=torch.bfloat16).to(\"cuda:0\"),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8973a435",
   "metadata": {},
   "source": [
    "### Test Loaded CLT encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60b75b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 7, 768])\n",
      "cuda:0 torch.bfloat16\n",
      "layer 0 nnz: 426\n",
      "layer 1 nnz: 204\n",
      "layer 2 nnz: 107\n",
      "layer 3 nnz: 94\n",
      "layer 4 nnz: 104\n",
      "layer 5 nnz: 72\n",
      "layer 6 nnz: 88\n",
      "layer 7 nnz: 36\n",
      "layer 8 nnz: 35\n",
      "layer 9 nnz: 18\n",
      "layer 10 nnz: 14\n",
      "layer 11 nnz: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(indices=tensor([[   0,    0,    0,  ...,   10,   11,   11],\n",
       "                        [   1,    1,    1,  ...,    6,    1,    6],\n",
       "                        [  71,  193,  330,  ..., 9154, 7738,  433]]),\n",
       "        values=tensor([-0.7852,  1.4062,  1.7812,  ...,  1.3203,  1.1094,\n",
       "                        0.4297]),\n",
       "        device='cuda:0', size=(12, 7, 10000), nnz=1200, dtype=torch.bfloat16,\n",
       "        layout=torch.sparse_coo, grad_fn=<CoalesceBackward0>),\n",
       " tensor([[-1.9409e-02, -1.8677e-02, -5.5420e-02,  ...,  2.7222e-02,\n",
       "           2.3438e-01, -2.4609e-01],\n",
       "         [-2.0447e-03,  3.7109e-02,  6.4697e-03,  ..., -4.1797e-01,\n",
       "          -2.8516e-01,  6.2988e-02],\n",
       "         [-2.6978e-02, -1.0193e-02,  6.5613e-04,  ..., -4.7656e-01,\n",
       "          -2.8564e-02, -1.9824e-01],\n",
       "         ...,\n",
       "         [ 2.1210e-03,  1.1520e-03,  6.0730e-03,  ..., -2.9907e-03,\n",
       "          -1.3885e-03,  5.0964e-03],\n",
       "         [-2.5787e-03,  1.1826e-03,  5.6152e-03,  ...,  4.8218e-03,\n",
       "           5.2795e-03,  4.4861e-03],\n",
       "         [-1.7700e-03,  2.0695e-04,  3.0975e-03,  ...,  1.2436e-03,\n",
       "           5.0049e-03, -2.8839e-03]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        grad_fn=<CatBackward0>))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_acts_clt = einops.rearrange(in_acts, \"b l d -> l b d\")\n",
    "assert in_acts_clt.shape == (12, 7, 768), in_acts_clt.shape\n",
    "\n",
    "in_acts_clt = in_acts_clt.to(\"cuda:0\")\n",
    "\n",
    "print(in_acts_clt.shape)\n",
    "print(in_acts_clt.device, in_acts_clt.dtype)\n",
    "\n",
    "circuit_tracer_transcoder.encode_sparse(in_acts_clt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d5efd4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 12, 768])\n",
      "cuda:0 torch.bfloat16\n",
      "layer 0 nnz: 426\n",
      "layer 1 nnz: 204\n",
      "layer 2 nnz: 107\n",
      "layer 3 nnz: 94\n",
      "layer 4 nnz: 104\n",
      "layer 5 nnz: 72\n",
      "layer 6 nnz: 88\n",
      "layer 7 nnz: 36\n",
      "layer 8 nnz: 35\n",
      "layer 9 nnz: 18\n",
      "layer 10 nnz: 14\n",
      "layer 11 nnz: 2\n",
      "nnz features: 1200\n",
      "torch.Size([12, 7, 10000])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'activation_matrix': tensor(indices=tensor([[   0,    0,    0,  ...,   10,   11,   11],\n",
       "                        [   1,    1,    1,  ...,    6,    1,    6],\n",
       "                        [  71,  193,  330,  ..., 9154, 7738,  433]]),\n",
       "        values=tensor([-0.7852,  1.4062,  1.7812,  ...,  1.3203,  1.1094,\n",
       "                        0.4297]),\n",
       "        device='cuda:0', size=(12, 7, 10000), nnz=1200, dtype=torch.bfloat16,\n",
       "        layout=torch.sparse_coo, grad_fn=<CoalesceBackward0>),\n",
       " 'reconstruction': tensor([[[-3.6621e-02,  9.7656e-02,  5.9814e-03,  ..., -6.0547e-02,\n",
       "           -5.7373e-02, -1.0986e-01],\n",
       "          [-1.9531e+00,  6.2109e-01, -1.5625e+00,  ...,  1.0547e+00,\n",
       "            1.2939e-02, -2.5977e-01],\n",
       "          [ 4.8340e-02,  7.9688e-01,  1.2695e-01,  ..., -6.1719e-01,\n",
       "            7.6953e-01, -5.2490e-02],\n",
       "          ...,\n",
       "          [-1.9688e+00,  1.0312e+00,  4.0430e-01,  ...,  2.0117e-01,\n",
       "            1.2969e+00, -4.1406e-01],\n",
       "          [-1.1016e+00,  3.1641e-01, -2.0312e-01,  ..., -1.9062e+00,\n",
       "            1.0312e+00, -5.5078e-01],\n",
       "          [-1.2578e+00,  4.8242e-01, -1.0625e+00,  ...,  1.1641e+00,\n",
       "            7.5195e-02,  6.9531e-01]],\n",
       " \n",
       "         [[-4.6875e-02, -5.6885e-02,  5.7373e-03,  ...,  6.4453e-02,\n",
       "            5.8350e-02, -4.2480e-02],\n",
       "          [-2.6758e-01,  1.1562e+00, -3.1836e-01,  ...,  7.1875e-01,\n",
       "            1.1406e+00, -2.3633e-01],\n",
       "          [-3.2471e-02,  1.0703e+00,  8.9844e-01,  ...,  6.1719e-01,\n",
       "            6.9922e-01,  7.5391e-01],\n",
       "          ...,\n",
       "          [-2.8076e-02,  1.0859e+00,  6.2500e-01,  ...,  4.6680e-01,\n",
       "            9.6484e-01,  1.4844e+00],\n",
       "          [-4.9219e-01,  4.0820e-01,  1.0625e+00,  ...,  1.1484e+00,\n",
       "            9.0625e-01,  4.1797e-01],\n",
       "          [-3.1445e-01,  1.3379e-01,  7.7734e-01,  ...,  1.1953e+00,\n",
       "            9.4922e-01,  4.7266e-01]],\n",
       " \n",
       "         [[-1.4038e-02, -4.1016e-02,  2.8442e-02,  ..., -1.6357e-02,\n",
       "            1.1597e-02, -2.0752e-03],\n",
       "          [-3.7109e-01,  1.7969e-01, -5.2734e-01,  ..., -1.5391e+00,\n",
       "            1.0400e-01,  5.4297e-01],\n",
       "          [ 1.7773e-01, -1.6699e-01,  2.8906e-01,  ..., -1.7773e-01,\n",
       "            2.9492e-01,  6.0156e-01],\n",
       "          ...,\n",
       "          [-5.0391e-01, -1.6504e-01, -1.5918e-01,  ..., -1.2188e+00,\n",
       "            1.5137e-02,  3.7695e-01],\n",
       "          [-2.0508e-01,  5.4688e-01, -3.6719e-01,  ..., -2.7539e-01,\n",
       "           -3.7109e-02, -8.1543e-02],\n",
       "          [-1.9727e-01, -7.0312e-01,  1.2451e-01,  ..., -4.2383e-01,\n",
       "           -3.0664e-01,  8.9844e-02]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 4.8523e-03,  2.9907e-02, -2.6367e-01,  ...,  1.5076e-02,\n",
       "            1.1572e-01, -1.3379e-01],\n",
       "          [-4.5117e-01,  3.6328e-01,  8.1250e-01,  ..., -3.2422e-01,\n",
       "            1.5391e+00, -2.4707e-01],\n",
       "          [-6.1719e-01,  2.7344e-01,  1.0625e+00,  ..., -2.8906e-01,\n",
       "            4.3750e-01, -2.4609e-01],\n",
       "          ...,\n",
       "          [-1.4355e-01,  4.6875e-01,  2.5586e-01,  ..., -2.5977e-01,\n",
       "            1.8516e+00, -7.9297e-01],\n",
       "          [ 1.0156e+00,  3.3789e-01,  1.1250e+00,  ...,  1.3477e-01,\n",
       "            1.6992e-01,  8.5938e-01],\n",
       "          [-9.8438e-01,  8.7109e-01, -8.5938e-02,  ..., -9.5703e-01,\n",
       "            8.4961e-02, -9.6680e-02]],\n",
       " \n",
       "         [[-1.5527e-01,  1.5332e-01, -2.9688e-01,  ...,  6.4453e-02,\n",
       "            8.1055e-02, -2.4512e-01],\n",
       "          [-2.2852e-01,  1.2500e-01,  1.5078e+00,  ..., -2.2969e+00,\n",
       "            6.4453e-01,  3.8672e-01],\n",
       "          [-1.9531e-03, -6.7969e-01,  1.8750e+00,  ..., -4.3164e-01,\n",
       "           -3.2031e-01, -9.6680e-02],\n",
       "          ...,\n",
       "          [ 3.1641e-01,  1.2031e+00,  4.8438e-01,  ..., -1.6328e+00,\n",
       "            1.3047e+00,  7.0703e-01],\n",
       "          [-5.4297e-01, -3.0859e-01,  4.5312e-01,  ..., -3.8477e-01,\n",
       "           -1.3984e+00,  3.4375e-01],\n",
       "          [-1.3359e+00,  8.1250e-01, -6.6406e-01,  ...,  5.9375e-01,\n",
       "            1.2656e+00,  2.5391e-01]],\n",
       " \n",
       "         [[ 2.2339e-02,  3.0078e-01, -2.5195e-01,  ...,  5.0049e-02,\n",
       "           -1.1719e-01,  8.3008e-03],\n",
       "          [-1.4375e+00,  9.2188e-01,  1.9219e+00,  ...,  5.0391e-01,\n",
       "           -1.4609e+00, -1.9727e-01],\n",
       "          [ 4.8828e-01, -9.9609e-01,  2.1719e+00,  ...,  3.1250e-01,\n",
       "            1.1094e+00,  1.8164e-01],\n",
       "          ...,\n",
       "          [ 4.3359e-01,  3.9258e-01,  9.1406e-01,  ..., -1.1484e+00,\n",
       "           -6.4844e-01, -8.6426e-02],\n",
       "          [ 8.8281e-01,  4.1797e-01,  1.4531e+00,  ..., -1.0547e+00,\n",
       "           -1.4297e+00,  3.2812e-01],\n",
       "          [-1.0625e+00,  5.2344e-01,  1.8438e+00,  ..., -7.2656e-01,\n",
       "           -1.0791e-01,  2.0117e-01]]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        grad_fn=<AddBackward0>),\n",
       " 'encoder_vecs': tensor([[-1.9409e-02, -1.8677e-02, -5.5420e-02,  ...,  2.7222e-02,\n",
       "           2.3438e-01, -2.4609e-01],\n",
       "         [-2.0447e-03,  3.7109e-02,  6.4697e-03,  ..., -4.1797e-01,\n",
       "          -2.8516e-01,  6.2988e-02],\n",
       "         [-2.6978e-02, -1.0193e-02,  6.5613e-04,  ..., -4.7656e-01,\n",
       "          -2.8564e-02, -1.9824e-01],\n",
       "         ...,\n",
       "         [ 2.1210e-03,  1.1520e-03,  6.0730e-03,  ..., -2.9907e-03,\n",
       "          -1.3885e-03,  5.0964e-03],\n",
       "         [-2.5787e-03,  1.1826e-03,  5.6152e-03,  ...,  4.8218e-03,\n",
       "           5.2795e-03,  4.4861e-03],\n",
       "         [-1.7700e-03,  2.0695e-04,  3.0975e-03,  ...,  1.2436e-03,\n",
       "           5.0049e-03, -2.8839e-03]], device='cuda:0', dtype=torch.bfloat16,\n",
       "        grad_fn=<CatBackward0>),\n",
       " 'decoder_vecs': tensor([[-0.0295, -0.0025, -0.0366,  ...,  0.0030, -0.0586,  0.0383],\n",
       "         [ 0.0062, -0.0219, -0.0461,  ..., -0.0248, -0.0233, -0.0234],\n",
       "         [-0.0356, -0.0102, -0.0253,  ...,  0.0181, -0.0050, -0.0097],\n",
       "         ...,\n",
       "         [ 0.0645,  0.2080,  0.0251,  ...,  0.2402, -0.1494,  0.2539],\n",
       "         [-0.6055,  0.2598,  0.0117,  ...,  0.3906, -0.2422, -0.0237],\n",
       "         [ 0.0732,  0.1108,  0.0193,  ...,  0.0023,  0.0161,  0.0840]],\n",
       "        device='cuda:0', dtype=torch.bfloat16, grad_fn=<CatBackward0>),\n",
       " 'encoder_to_decoder_map': tensor([   0,    0,    0,  ..., 1197, 1198, 1199], device='cuda:0'),\n",
       " 'decoder_locations': tensor([[ 0,  1,  2,  ..., 11, 11, 11],\n",
       "         [ 1,  1,  1,  ...,  6,  1,  6]], device='cuda:0')}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(in_acts.shape)\n",
    "print(in_acts_clt.device, in_acts_clt.dtype)\n",
    "circuit_tracer_transcoder.compute_attribution_components(in_acts_clt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412783b9",
   "metadata": {},
   "source": [
    "### Test with ReplacementModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0db2198d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "['W_enc_0', 'b_dec_0', 'b_enc_0', 'threshold_0']\n",
      "['W_enc_1', 'b_dec_1', 'b_enc_1', 'threshold_1']\n",
      "['W_enc_2', 'b_dec_2', 'b_enc_2', 'threshold_2']\n",
      "['W_enc_3', 'b_dec_3', 'b_enc_3', 'threshold_3']\n",
      "['W_enc_4', 'b_dec_4', 'b_enc_4', 'threshold_4']\n",
      "['W_enc_5', 'b_dec_5', 'b_enc_5', 'threshold_5']\n",
      "['W_enc_6', 'b_dec_6', 'b_enc_6', 'threshold_6']\n",
      "['W_enc_7', 'b_dec_7', 'b_enc_7', 'threshold_7']\n",
      "['W_enc_8', 'b_dec_8', 'b_enc_8', 'threshold_8']\n",
      "['W_enc_9', 'b_dec_9', 'b_enc_9', 'threshold_9']\n",
      "['W_enc_10', 'b_dec_10', 'b_enc_10', 'threshold_10']\n",
      "['W_enc_11', 'b_dec_11', 'b_enc_11', 'threshold_11']\n",
      "dict_keys(['b_dec', 'b_enc', 'activation_function.threshold', 'W_enc', 'W_dec.0', 'W_dec.1', 'W_dec.2', 'W_dec.3', 'W_dec.4', 'W_dec.5', 'W_dec.6', 'W_dec.7', 'W_dec.8', 'W_dec.9', 'W_dec.10', 'W_dec.11'])\n",
      "cuda:0 torch.bfloat16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b23ff4f5c51409d955f08b2997ef3b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9262fc522f4f4334b00bb0ab119c66e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2 into HookedTransformer\n",
      "cuda:0 torch.float32\n",
      "{'hook_embed': HookPoint(), 'hook_pos_embed': HookPoint(), 'blocks.0.ln1.hook_scale': HookPoint(), 'blocks.0.ln1.hook_normalized': HookPoint(), 'blocks.0.ln2.hook_scale': HookPoint(), 'blocks.0.ln2.hook_normalized': HookPoint(), 'blocks.0.attn.hook_k': HookPoint(), 'blocks.0.attn.hook_q': HookPoint(), 'blocks.0.attn.hook_v': HookPoint(), 'blocks.0.attn.hook_z': HookPoint(), 'blocks.0.attn.hook_attn_scores': HookPoint(), 'blocks.0.attn.hook_pattern': HookPoint(), 'blocks.0.attn.hook_result': HookPoint(), 'blocks.0.mlp.old_mlp.hook_pre': HookPoint(), 'blocks.0.mlp.old_mlp.hook_post': HookPoint(), 'blocks.0.mlp.hook_in': HookPoint(), 'blocks.0.mlp.hook_out': HookPoint(), 'blocks.0.hook_attn_in': HookPoint(), 'blocks.0.hook_q_input': HookPoint(), 'blocks.0.hook_k_input': HookPoint(), 'blocks.0.hook_v_input': HookPoint(), 'blocks.0.hook_mlp_in': HookPoint(), 'blocks.0.hook_attn_out': HookPoint(), 'blocks.0.hook_mlp_out': HookPoint(\n",
      "  (hook_out_grad): HookPoint()\n",
      "), 'blocks.0.hook_mlp_out.hook_out_grad': HookPoint(), 'blocks.0.hook_resid_pre': HookPoint(), 'blocks.0.hook_resid_mid': HookPoint(), 'blocks.0.hook_resid_post': HookPoint(), 'blocks.1.ln1.hook_scale': HookPoint(), 'blocks.1.ln1.hook_normalized': HookPoint(), 'blocks.1.ln2.hook_scale': HookPoint(), 'blocks.1.ln2.hook_normalized': HookPoint(), 'blocks.1.attn.hook_k': HookPoint(), 'blocks.1.attn.hook_q': HookPoint(), 'blocks.1.attn.hook_v': HookPoint(), 'blocks.1.attn.hook_z': HookPoint(), 'blocks.1.attn.hook_attn_scores': HookPoint(), 'blocks.1.attn.hook_pattern': HookPoint(), 'blocks.1.attn.hook_result': HookPoint(), 'blocks.1.mlp.old_mlp.hook_pre': HookPoint(), 'blocks.1.mlp.old_mlp.hook_post': HookPoint(), 'blocks.1.mlp.hook_in': HookPoint(), 'blocks.1.mlp.hook_out': HookPoint(), 'blocks.1.hook_attn_in': HookPoint(), 'blocks.1.hook_q_input': HookPoint(), 'blocks.1.hook_k_input': HookPoint(), 'blocks.1.hook_v_input': HookPoint(), 'blocks.1.hook_mlp_in': HookPoint(), 'blocks.1.hook_attn_out': HookPoint(), 'blocks.1.hook_mlp_out': HookPoint(\n",
      "  (hook_out_grad): HookPoint()\n",
      "), 'blocks.1.hook_mlp_out.hook_out_grad': HookPoint(), 'blocks.1.hook_resid_pre': HookPoint(), 'blocks.1.hook_resid_mid': HookPoint(), 'blocks.1.hook_resid_post': HookPoint(), 'blocks.2.ln1.hook_scale': HookPoint(), 'blocks.2.ln1.hook_normalized': HookPoint(), 'blocks.2.ln2.hook_scale': HookPoint(), 'blocks.2.ln2.hook_normalized': HookPoint(), 'blocks.2.attn.hook_k': HookPoint(), 'blocks.2.attn.hook_q': HookPoint(), 'blocks.2.attn.hook_v': HookPoint(), 'blocks.2.attn.hook_z': HookPoint(), 'blocks.2.attn.hook_attn_scores': HookPoint(), 'blocks.2.attn.hook_pattern': HookPoint(), 'blocks.2.attn.hook_result': HookPoint(), 'blocks.2.mlp.old_mlp.hook_pre': HookPoint(), 'blocks.2.mlp.old_mlp.hook_post': HookPoint(), 'blocks.2.mlp.hook_in': HookPoint(), 'blocks.2.mlp.hook_out': HookPoint(), 'blocks.2.hook_attn_in': HookPoint(), 'blocks.2.hook_q_input': HookPoint(), 'blocks.2.hook_k_input': HookPoint(), 'blocks.2.hook_v_input': HookPoint(), 'blocks.2.hook_mlp_in': HookPoint(), 'blocks.2.hook_attn_out': HookPoint(), 'blocks.2.hook_mlp_out': HookPoint(\n",
      "  (hook_out_grad): HookPoint()\n",
      "), 'blocks.2.hook_mlp_out.hook_out_grad': HookPoint(), 'blocks.2.hook_resid_pre': HookPoint(), 'blocks.2.hook_resid_mid': HookPoint(), 'blocks.2.hook_resid_post': HookPoint(), 'blocks.3.ln1.hook_scale': HookPoint(), 'blocks.3.ln1.hook_normalized': HookPoint(), 'blocks.3.ln2.hook_scale': HookPoint(), 'blocks.3.ln2.hook_normalized': HookPoint(), 'blocks.3.attn.hook_k': HookPoint(), 'blocks.3.attn.hook_q': HookPoint(), 'blocks.3.attn.hook_v': HookPoint(), 'blocks.3.attn.hook_z': HookPoint(), 'blocks.3.attn.hook_attn_scores': HookPoint(), 'blocks.3.attn.hook_pattern': HookPoint(), 'blocks.3.attn.hook_result': HookPoint(), 'blocks.3.mlp.old_mlp.hook_pre': HookPoint(), 'blocks.3.mlp.old_mlp.hook_post': HookPoint(), 'blocks.3.mlp.hook_in': HookPoint(), 'blocks.3.mlp.hook_out': HookPoint(), 'blocks.3.hook_attn_in': HookPoint(), 'blocks.3.hook_q_input': HookPoint(), 'blocks.3.hook_k_input': HookPoint(), 'blocks.3.hook_v_input': HookPoint(), 'blocks.3.hook_mlp_in': HookPoint(), 'blocks.3.hook_attn_out': HookPoint(), 'blocks.3.hook_mlp_out': HookPoint(\n",
      "  (hook_out_grad): HookPoint()\n",
      "), 'blocks.3.hook_mlp_out.hook_out_grad': HookPoint(), 'blocks.3.hook_resid_pre': HookPoint(), 'blocks.3.hook_resid_mid': HookPoint(), 'blocks.3.hook_resid_post': HookPoint(), 'blocks.4.ln1.hook_scale': HookPoint(), 'blocks.4.ln1.hook_normalized': HookPoint(), 'blocks.4.ln2.hook_scale': HookPoint(), 'blocks.4.ln2.hook_normalized': HookPoint(), 'blocks.4.attn.hook_k': HookPoint(), 'blocks.4.attn.hook_q': HookPoint(), 'blocks.4.attn.hook_v': HookPoint(), 'blocks.4.attn.hook_z': HookPoint(), 'blocks.4.attn.hook_attn_scores': HookPoint(), 'blocks.4.attn.hook_pattern': HookPoint(), 'blocks.4.attn.hook_result': HookPoint(), 'blocks.4.mlp.old_mlp.hook_pre': HookPoint(), 'blocks.4.mlp.old_mlp.hook_post': HookPoint(), 'blocks.4.mlp.hook_in': HookPoint(), 'blocks.4.mlp.hook_out': HookPoint(), 'blocks.4.hook_attn_in': HookPoint(), 'blocks.4.hook_q_input': HookPoint(), 'blocks.4.hook_k_input': HookPoint(), 'blocks.4.hook_v_input': HookPoint(), 'blocks.4.hook_mlp_in': HookPoint(), 'blocks.4.hook_attn_out': HookPoint(), 'blocks.4.hook_mlp_out': HookPoint(\n",
      "  (hook_out_grad): HookPoint()\n",
      "), 'blocks.4.hook_mlp_out.hook_out_grad': HookPoint(), 'blocks.4.hook_resid_pre': HookPoint(), 'blocks.4.hook_resid_mid': HookPoint(), 'blocks.4.hook_resid_post': HookPoint(), 'blocks.5.ln1.hook_scale': HookPoint(), 'blocks.5.ln1.hook_normalized': HookPoint(), 'blocks.5.ln2.hook_scale': HookPoint(), 'blocks.5.ln2.hook_normalized': HookPoint(), 'blocks.5.attn.hook_k': HookPoint(), 'blocks.5.attn.hook_q': HookPoint(), 'blocks.5.attn.hook_v': HookPoint(), 'blocks.5.attn.hook_z': HookPoint(), 'blocks.5.attn.hook_attn_scores': HookPoint(), 'blocks.5.attn.hook_pattern': HookPoint(), 'blocks.5.attn.hook_result': HookPoint(), 'blocks.5.mlp.old_mlp.hook_pre': HookPoint(), 'blocks.5.mlp.old_mlp.hook_post': HookPoint(), 'blocks.5.mlp.hook_in': HookPoint(), 'blocks.5.mlp.hook_out': HookPoint(), 'blocks.5.hook_attn_in': HookPoint(), 'blocks.5.hook_q_input': HookPoint(), 'blocks.5.hook_k_input': HookPoint(), 'blocks.5.hook_v_input': HookPoint(), 'blocks.5.hook_mlp_in': HookPoint(), 'blocks.5.hook_attn_out': HookPoint(), 'blocks.5.hook_mlp_out': HookPoint(\n",
      "  (hook_out_grad): HookPoint()\n",
      "), 'blocks.5.hook_mlp_out.hook_out_grad': HookPoint(), 'blocks.5.hook_resid_pre': HookPoint(), 'blocks.5.hook_resid_mid': HookPoint(), 'blocks.5.hook_resid_post': HookPoint(), 'blocks.6.ln1.hook_scale': HookPoint(), 'blocks.6.ln1.hook_normalized': HookPoint(), 'blocks.6.ln2.hook_scale': HookPoint(), 'blocks.6.ln2.hook_normalized': HookPoint(), 'blocks.6.attn.hook_k': HookPoint(), 'blocks.6.attn.hook_q': HookPoint(), 'blocks.6.attn.hook_v': HookPoint(), 'blocks.6.attn.hook_z': HookPoint(), 'blocks.6.attn.hook_attn_scores': HookPoint(), 'blocks.6.attn.hook_pattern': HookPoint(), 'blocks.6.attn.hook_result': HookPoint(), 'blocks.6.mlp.old_mlp.hook_pre': HookPoint(), 'blocks.6.mlp.old_mlp.hook_post': HookPoint(), 'blocks.6.mlp.hook_in': HookPoint(), 'blocks.6.mlp.hook_out': HookPoint(), 'blocks.6.hook_attn_in': HookPoint(), 'blocks.6.hook_q_input': HookPoint(), 'blocks.6.hook_k_input': HookPoint(), 'blocks.6.hook_v_input': HookPoint(), 'blocks.6.hook_mlp_in': HookPoint(), 'blocks.6.hook_attn_out': HookPoint(), 'blocks.6.hook_mlp_out': HookPoint(\n",
      "  (hook_out_grad): HookPoint()\n",
      "), 'blocks.6.hook_mlp_out.hook_out_grad': HookPoint(), 'blocks.6.hook_resid_pre': HookPoint(), 'blocks.6.hook_resid_mid': HookPoint(), 'blocks.6.hook_resid_post': HookPoint(), 'blocks.7.ln1.hook_scale': HookPoint(), 'blocks.7.ln1.hook_normalized': HookPoint(), 'blocks.7.ln2.hook_scale': HookPoint(), 'blocks.7.ln2.hook_normalized': HookPoint(), 'blocks.7.attn.hook_k': HookPoint(), 'blocks.7.attn.hook_q': HookPoint(), 'blocks.7.attn.hook_v': HookPoint(), 'blocks.7.attn.hook_z': HookPoint(), 'blocks.7.attn.hook_attn_scores': HookPoint(), 'blocks.7.attn.hook_pattern': HookPoint(), 'blocks.7.attn.hook_result': HookPoint(), 'blocks.7.mlp.old_mlp.hook_pre': HookPoint(), 'blocks.7.mlp.old_mlp.hook_post': HookPoint(), 'blocks.7.mlp.hook_in': HookPoint(), 'blocks.7.mlp.hook_out': HookPoint(), 'blocks.7.hook_attn_in': HookPoint(), 'blocks.7.hook_q_input': HookPoint(), 'blocks.7.hook_k_input': HookPoint(), 'blocks.7.hook_v_input': HookPoint(), 'blocks.7.hook_mlp_in': HookPoint(), 'blocks.7.hook_attn_out': HookPoint(), 'blocks.7.hook_mlp_out': HookPoint(\n",
      "  (hook_out_grad): HookPoint()\n",
      "), 'blocks.7.hook_mlp_out.hook_out_grad': HookPoint(), 'blocks.7.hook_resid_pre': HookPoint(), 'blocks.7.hook_resid_mid': HookPoint(), 'blocks.7.hook_resid_post': HookPoint(), 'blocks.8.ln1.hook_scale': HookPoint(), 'blocks.8.ln1.hook_normalized': HookPoint(), 'blocks.8.ln2.hook_scale': HookPoint(), 'blocks.8.ln2.hook_normalized': HookPoint(), 'blocks.8.attn.hook_k': HookPoint(), 'blocks.8.attn.hook_q': HookPoint(), 'blocks.8.attn.hook_v': HookPoint(), 'blocks.8.attn.hook_z': HookPoint(), 'blocks.8.attn.hook_attn_scores': HookPoint(), 'blocks.8.attn.hook_pattern': HookPoint(), 'blocks.8.attn.hook_result': HookPoint(), 'blocks.8.mlp.old_mlp.hook_pre': HookPoint(), 'blocks.8.mlp.old_mlp.hook_post': HookPoint(), 'blocks.8.mlp.hook_in': HookPoint(), 'blocks.8.mlp.hook_out': HookPoint(), 'blocks.8.hook_attn_in': HookPoint(), 'blocks.8.hook_q_input': HookPoint(), 'blocks.8.hook_k_input': HookPoint(), 'blocks.8.hook_v_input': HookPoint(), 'blocks.8.hook_mlp_in': HookPoint(), 'blocks.8.hook_attn_out': HookPoint(), 'blocks.8.hook_mlp_out': HookPoint(\n",
      "  (hook_out_grad): HookPoint()\n",
      "), 'blocks.8.hook_mlp_out.hook_out_grad': HookPoint(), 'blocks.8.hook_resid_pre': HookPoint(), 'blocks.8.hook_resid_mid': HookPoint(), 'blocks.8.hook_resid_post': HookPoint(), 'blocks.9.ln1.hook_scale': HookPoint(), 'blocks.9.ln1.hook_normalized': HookPoint(), 'blocks.9.ln2.hook_scale': HookPoint(), 'blocks.9.ln2.hook_normalized': HookPoint(), 'blocks.9.attn.hook_k': HookPoint(), 'blocks.9.attn.hook_q': HookPoint(), 'blocks.9.attn.hook_v': HookPoint(), 'blocks.9.attn.hook_z': HookPoint(), 'blocks.9.attn.hook_attn_scores': HookPoint(), 'blocks.9.attn.hook_pattern': HookPoint(), 'blocks.9.attn.hook_result': HookPoint(), 'blocks.9.mlp.old_mlp.hook_pre': HookPoint(), 'blocks.9.mlp.old_mlp.hook_post': HookPoint(), 'blocks.9.mlp.hook_in': HookPoint(), 'blocks.9.mlp.hook_out': HookPoint(), 'blocks.9.hook_attn_in': HookPoint(), 'blocks.9.hook_q_input': HookPoint(), 'blocks.9.hook_k_input': HookPoint(), 'blocks.9.hook_v_input': HookPoint(), 'blocks.9.hook_mlp_in': HookPoint(), 'blocks.9.hook_attn_out': HookPoint(), 'blocks.9.hook_mlp_out': HookPoint(\n",
      "  (hook_out_grad): HookPoint()\n",
      "), 'blocks.9.hook_mlp_out.hook_out_grad': HookPoint(), 'blocks.9.hook_resid_pre': HookPoint(), 'blocks.9.hook_resid_mid': HookPoint(), 'blocks.9.hook_resid_post': HookPoint(), 'blocks.10.ln1.hook_scale': HookPoint(), 'blocks.10.ln1.hook_normalized': HookPoint(), 'blocks.10.ln2.hook_scale': HookPoint(), 'blocks.10.ln2.hook_normalized': HookPoint(), 'blocks.10.attn.hook_k': HookPoint(), 'blocks.10.attn.hook_q': HookPoint(), 'blocks.10.attn.hook_v': HookPoint(), 'blocks.10.attn.hook_z': HookPoint(), 'blocks.10.attn.hook_attn_scores': HookPoint(), 'blocks.10.attn.hook_pattern': HookPoint(), 'blocks.10.attn.hook_result': HookPoint(), 'blocks.10.mlp.old_mlp.hook_pre': HookPoint(), 'blocks.10.mlp.old_mlp.hook_post': HookPoint(), 'blocks.10.mlp.hook_in': HookPoint(), 'blocks.10.mlp.hook_out': HookPoint(), 'blocks.10.hook_attn_in': HookPoint(), 'blocks.10.hook_q_input': HookPoint(), 'blocks.10.hook_k_input': HookPoint(), 'blocks.10.hook_v_input': HookPoint(), 'blocks.10.hook_mlp_in': HookPoint(), 'blocks.10.hook_attn_out': HookPoint(), 'blocks.10.hook_mlp_out': HookPoint(\n",
      "  (hook_out_grad): HookPoint()\n",
      "), 'blocks.10.hook_mlp_out.hook_out_grad': HookPoint(), 'blocks.10.hook_resid_pre': HookPoint(), 'blocks.10.hook_resid_mid': HookPoint(), 'blocks.10.hook_resid_post': HookPoint(), 'blocks.11.ln1.hook_scale': HookPoint(), 'blocks.11.ln1.hook_normalized': HookPoint(), 'blocks.11.ln2.hook_scale': HookPoint(), 'blocks.11.ln2.hook_normalized': HookPoint(), 'blocks.11.attn.hook_k': HookPoint(), 'blocks.11.attn.hook_q': HookPoint(), 'blocks.11.attn.hook_v': HookPoint(), 'blocks.11.attn.hook_z': HookPoint(), 'blocks.11.attn.hook_attn_scores': HookPoint(), 'blocks.11.attn.hook_pattern': HookPoint(), 'blocks.11.attn.hook_result': HookPoint(), 'blocks.11.mlp.old_mlp.hook_pre': HookPoint(), 'blocks.11.mlp.old_mlp.hook_post': HookPoint(), 'blocks.11.mlp.hook_in': HookPoint(), 'blocks.11.mlp.hook_out': HookPoint(), 'blocks.11.hook_attn_in': HookPoint(), 'blocks.11.hook_q_input': HookPoint(), 'blocks.11.hook_k_input': HookPoint(), 'blocks.11.hook_v_input': HookPoint(), 'blocks.11.hook_mlp_in': HookPoint(), 'blocks.11.hook_attn_out': HookPoint(), 'blocks.11.hook_mlp_out': HookPoint(\n",
      "  (hook_out_grad): HookPoint()\n",
      "), 'blocks.11.hook_mlp_out.hook_out_grad': HookPoint(), 'blocks.11.hook_resid_pre': HookPoint(), 'blocks.11.hook_resid_mid': HookPoint(), 'blocks.11.hook_resid_post': HookPoint(), 'ln_final.hook_scale': HookPoint(), 'ln_final.hook_normalized': HookPoint(), 'unembed.hook_pre': HookPoint(), 'unembed.hook_post': HookPoint()}\n"
     ]
    }
   ],
   "source": [
    "from circuit_tracer import ReplacementModel\n",
    "from transformer_lens.loading_from_pretrained import get_pretrained_model_config\n",
    "\n",
    "# copy transcoder \n",
    "circuit_tracer_transcoder_copy, _ = load_clt(\n",
    "    clt_path=save_dir.as_posix(),\n",
    "    lazy_decoder=False,\n",
    "    lazy_encoder=False,\n",
    "    feature_input_hook=feature_input_hook,\n",
    "    feature_output_hook=feature_output_hook,\n",
    "    dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "print(circuit_tracer_transcoder_copy.device, circuit_tracer_transcoder_copy.dtype)\n",
    "config = get_pretrained_model_config(\"gpt2\")\n",
    "config.dtype=torch.bfloat16\n",
    "rm = ReplacementModel.from_pretrained_and_transcoders(\n",
    "    \"gpt2\",\n",
    "    circuit_tracer_transcoder_copy,\n",
    ")\n",
    "\n",
    "print(rm.transcoders.device, rm.transcoders.dtype)\n",
    "print(rm.hook_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ff4d213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('blocks.0.hook_resid_mid', functools.partial(<function HookedRootModule.get_caching_hooks.<locals>.save_hook at 0x7ae5023fd800>, is_backward=False)), ('blocks.1.hook_resid_mid', functools.partial(<function HookedRootModule.get_caching_hooks.<locals>.save_hook at 0x7ae5023fd800>, is_backward=False)), ('blocks.2.hook_resid_mid', functools.partial(<function HookedRootModule.get_caching_hooks.<locals>.save_hook at 0x7ae5023fd800>, is_backward=False)), ('blocks.3.hook_resid_mid', functools.partial(<function HookedRootModule.get_caching_hooks.<locals>.save_hook at 0x7ae5023fd800>, is_backward=False)), ('blocks.4.hook_resid_mid', functools.partial(<function HookedRootModule.get_caching_hooks.<locals>.save_hook at 0x7ae5023fd800>, is_backward=False)), ('blocks.5.hook_resid_mid', functools.partial(<function HookedRootModule.get_caching_hooks.<locals>.save_hook at 0x7ae5023fd800>, is_backward=False)), ('blocks.6.hook_resid_mid', functools.partial(<function HookedRootModule.get_caching_hooks.<locals>.save_hook at 0x7ae5023fd800>, is_backward=False)), ('blocks.7.hook_resid_mid', functools.partial(<function HookedRootModule.get_caching_hooks.<locals>.save_hook at 0x7ae5023fd800>, is_backward=False)), ('blocks.8.hook_resid_mid', functools.partial(<function HookedRootModule.get_caching_hooks.<locals>.save_hook at 0x7ae5023fd800>, is_backward=False)), ('blocks.9.hook_resid_mid', functools.partial(<function HookedRootModule.get_caching_hooks.<locals>.save_hook at 0x7ae5023fd800>, is_backward=False)), ('blocks.10.hook_resid_mid', functools.partial(<function HookedRootModule.get_caching_hooks.<locals>.save_hook at 0x7ae5023fd800>, is_backward=False)), ('blocks.11.hook_resid_mid', functools.partial(<function HookedRootModule.get_caching_hooks.<locals>.save_hook at 0x7ae5023fd800>, is_backward=False))]\n",
      "torch.Size([1, 8, 50257])\n",
      "dict_items([('blocks.0.hook_resid_mid', tensor([[[ 0.8292, -0.2081,  0.0887,  ..., -0.0029,  0.1603,  0.3562],\n",
      "         [-0.1627,  0.2027, -0.5368,  ...,  0.0968, -0.0061,  0.1409],\n",
      "         [-0.3465,  0.0869, -0.5563,  ...,  0.1135, -0.0570,  0.1199],\n",
      "         ...,\n",
      "         [-0.1875,  0.4008, -0.3190,  ..., -0.1480,  0.0055,  0.0641],\n",
      "         [ 1.6809,  0.5578, -0.5070,  ..., -0.1841,  0.2872,  0.2613],\n",
      "         [ 0.6528,  0.3823, -0.1777,  ...,  0.0927, -0.0343, -0.0222]]],\n",
      "       device='cuda:0')), ('blocks.1.hook_resid_mid', tensor([[[ 0.7366,  0.2633,  0.8380,  ...,  1.7356,  1.5534,  0.6067],\n",
      "         [-0.5045, -0.0267, -0.7114,  ..., -0.1848, -0.7491,  0.1695],\n",
      "         [-1.7334,  0.7541, -1.7714,  ...,  1.5820, -1.9192,  0.4845],\n",
      "         ...,\n",
      "         [-1.0849,  1.4963, -0.1123,  ...,  0.4767,  0.3309, -0.0391],\n",
      "         [ 2.0111,  0.8939, -1.4627,  ..., -1.8787,  0.2278, -0.1587],\n",
      "         [ 0.0421,  0.7707, -0.8557,  ...,  1.4787, -0.7605,  0.9899]]],\n",
      "       device='cuda:0')), ('blocks.2.hook_resid_mid', tensor([[[ 0.1488, -0.0781,  0.5468,  ...,  1.6689,  1.4880,  0.7661],\n",
      "         [-0.8259, -0.2939, -0.8941,  ..., -0.2092, -1.2692, -0.1108],\n",
      "         [-1.8970,  1.6090, -1.9269,  ...,  1.9306, -1.9026, -0.4079],\n",
      "         ...,\n",
      "         [-1.1005,  1.7253, -0.0383,  ...,  0.5634,  0.8792,  0.7951],\n",
      "         [ 1.4697,  0.5930, -1.6843,  ..., -1.3790,  0.4047, -0.5614],\n",
      "         [ 0.2322,  0.4183, -0.6936,  ...,  1.5644, -0.6832,  1.2189]]],\n",
      "       device='cuda:0')), ('blocks.3.hook_resid_mid', tensor([[[ 0.0661, -0.1998,  0.5140,  ...,  1.4456,  1.4002,  0.6470],\n",
      "         [-1.0289, -0.3439, -0.1235,  ..., -0.2292, -1.3801,  0.0214],\n",
      "         [-2.1646,  2.4593, -1.8518,  ...,  1.1662, -2.2947, -0.1005],\n",
      "         ...,\n",
      "         [-1.3023,  1.3682,  1.3973,  ..., -0.0248,  1.2654,  1.1106],\n",
      "         [ 0.9751,  1.2863, -1.5901,  ..., -1.4095,  0.1266, -0.3963],\n",
      "         [ 0.2027,  0.0645,  0.2270,  ...,  1.8477, -1.4379,  1.0276]]],\n",
      "       device='cuda:0')), ('blocks.4.hook_resid_mid', tensor([[[-0.0580, -0.3595,  0.4574,  ...,  1.3160,  1.2230,  0.6406],\n",
      "         [-2.1363, -0.6073,  0.0711,  ...,  0.4583, -1.1995,  0.7196],\n",
      "         [-3.6694,  1.7980, -3.0582,  ...,  2.2501, -3.4340,  0.4635],\n",
      "         ...,\n",
      "         [-1.6586,  0.7425,  0.8882,  ...,  1.1538,  0.6740,  1.4706],\n",
      "         [ 0.9481,  1.3355, -2.4056,  ..., -1.7796, -0.1907, -0.4598],\n",
      "         [-0.3690,  0.3992, -0.0730,  ...,  2.2794, -1.3240,  1.2353]]],\n",
      "       device='cuda:0')), ('blocks.5.hook_resid_mid', tensor([[[-0.1437, -0.3980,  0.4653,  ...,  1.2557,  1.1286,  0.5841],\n",
      "         [-2.2264, -0.4958,  0.1818,  ...,  0.8170, -1.5775,  1.1018],\n",
      "         [-4.1140,  2.5474, -3.6180,  ...,  1.9292, -4.2118,  0.7760],\n",
      "         ...,\n",
      "         [-2.2961,  1.4702,  1.1608,  ...,  1.1624,  0.2801,  1.7627],\n",
      "         [ 0.7102,  1.5051, -2.4009,  ..., -1.0501, -0.9454, -0.8125],\n",
      "         [ 0.1730,  0.4505,  0.5230,  ...,  3.3662, -0.8115,  1.7597]]],\n",
      "       device='cuda:0')), ('blocks.6.hook_resid_mid', tensor([[[-0.1418, -0.3710,  0.5526,  ...,  1.1364,  1.0140,  0.5661],\n",
      "         [-2.5741, -0.4803,  0.4509,  ...,  1.0593, -1.5936,  0.7250],\n",
      "         [-4.1928,  2.8387, -4.2037,  ...,  2.6937, -3.5340,  0.7354],\n",
      "         ...,\n",
      "         [-1.9225,  0.5152,  0.6427,  ...,  1.6845, -0.2169,  2.0397],\n",
      "         [ 1.4380,  1.3117, -1.7126,  ..., -0.9297, -0.0077, -0.7019],\n",
      "         [-0.1650,  0.4262,  0.3057,  ...,  4.4950, -1.5823,  2.7732]]],\n",
      "       device='cuda:0')), ('blocks.7.hook_resid_mid', tensor([[[-0.2448, -0.2811,  0.5022,  ...,  1.1156,  0.8833,  0.3835],\n",
      "         [-2.4570,  0.8735,  0.5153,  ...,  0.5349, -2.2505, -0.0874],\n",
      "         [-6.9050,  4.1731, -3.5826,  ...,  3.0283, -4.0174,  0.5070],\n",
      "         ...,\n",
      "         [-1.6423,  0.6971, -0.2637,  ...,  1.0385,  0.8479,  3.1449],\n",
      "         [ 2.2448,  0.6985, -2.0658,  ..., -1.3574, -0.2864, -0.4600],\n",
      "         [-0.5407,  1.7449, -0.9142,  ...,  4.4162, -0.3360,  4.1052]]],\n",
      "       device='cuda:0')), ('blocks.8.hook_resid_mid', tensor([[[-0.2317, -0.1742,  0.4076,  ...,  1.2093,  0.9779,  0.3468],\n",
      "         [-2.3272,  0.8944,  1.0235,  ...,  0.7030, -1.8648, -0.9032],\n",
      "         [-7.0494,  5.2281, -4.1065,  ...,  2.0068, -4.1265,  0.3011],\n",
      "         ...,\n",
      "         [-1.0423,  0.8841, -0.8168,  ...,  0.7086,  1.1515,  2.5642],\n",
      "         [ 2.4226,  0.2734, -2.7923,  ..., -2.6671,  0.6658,  0.2542],\n",
      "         [-0.1577,  2.4592, -1.3308,  ...,  3.5287, -1.5098,  5.1052]]],\n",
      "       device='cuda:0')), ('blocks.9.hook_resid_mid', tensor([[[-0.2822, -0.0332,  0.3085,  ...,  1.3752,  0.9603,  0.0852],\n",
      "         [-2.3929,  0.8874,  1.0884,  ...,  1.0155, -1.2947, -1.3692],\n",
      "         [-7.3202,  5.6661, -5.4029,  ...,  2.8207, -4.6241,  0.1844],\n",
      "         ...,\n",
      "         [-1.2294,  2.5105, -1.7207,  ...,  0.9849,  2.8533,  3.4939],\n",
      "         [ 2.6443,  0.1823, -2.7417,  ..., -1.1531,  0.9782,  1.3396],\n",
      "         [-0.3001,  3.6369, -0.4387,  ...,  3.9318, -0.6444,  4.0109]]],\n",
      "       device='cuda:0')), ('blocks.10.hook_resid_mid', tensor([[[-2.9332e-01,  2.8656e-02, -8.5813e-04,  ...,  1.3900e+00,\n",
      "           1.1820e+00, -1.1640e-01],\n",
      "         [-2.4854e+00,  7.7822e-01,  2.2521e+00,  ..., -1.2356e-01,\n",
      "          -2.6242e-01, -2.2910e+00],\n",
      "         [-8.0578e+00,  4.5745e+00, -7.5444e+00,  ...,  2.7251e+00,\n",
      "          -4.2399e+00, -1.0159e+00],\n",
      "         ...,\n",
      "         [-2.2039e+00,  3.8935e+00, -1.7146e+00,  ...,  1.6282e+00,\n",
      "           5.3636e+00,  1.2540e+00],\n",
      "         [ 2.9170e+00,  2.3938e+00, -2.3362e+00,  ...,  1.7417e-03,\n",
      "           9.3079e-01,  2.0680e+00],\n",
      "         [-1.1518e+00,  4.4683e+00, -3.3433e+00,  ...,  3.5590e+00,\n",
      "          -1.9450e-01,  4.3937e+00]]], device='cuda:0')), ('blocks.11.hook_resid_mid', tensor([[[-0.3818,  0.0473, -0.4384,  ...,  1.5397,  1.6579, -0.2553],\n",
      "         [-2.4054,  0.1560,  3.3125,  ...,  0.1850,  0.5278, -2.4760],\n",
      "         [-9.4641,  4.7007, -6.5114,  ...,  2.8988, -4.4499, -1.5477],\n",
      "         ...,\n",
      "         [ 1.4269,  3.2414,  0.5623,  ...,  1.0460,  5.8567, -1.0748],\n",
      "         [ 2.2601,  1.4785, -2.1479,  ...,  1.0913, -0.9739,  2.9741],\n",
      "         [-1.4892,  4.4865, -4.1967,  ...,  4.0651,  1.1076,  4.7898]]],\n",
      "       device='cuda:0'))])\n",
      "cuda:0 torch.float32\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if isinstance(prompt, str):\n",
    "    tokens = rm.ensure_tokenized(prompt)\n",
    "else:\n",
    "    tokens = prompt.squeeze()\n",
    "# COuld it be the caching hooks?\n",
    "mlp_in_cache, mlp_in_caching_hooks, _ = rm.get_caching_hooks(\n",
    "    lambda name: rm.feature_input_hook in name\n",
    ")\n",
    "print(mlp_in_caching_hooks)\n",
    "\n",
    "mlp_out_cache, mlp_out_caching_hooks, _ = rm.get_caching_hooks(\n",
    "    lambda name: rm.feature_output_hook in name\n",
    ")\n",
    "logits = rm.run_with_hooks(tokens, fwd_hooks=mlp_in_caching_hooks + mlp_out_caching_hooks)\n",
    "print(logits.shape)\n",
    "\n",
    "\n",
    "print(mlp_in_cache.items())\n",
    "\n",
    "mlp_in_cache = torch.cat(list(mlp_in_cache.values()), dim=0)\n",
    "mlp_out_cache = torch.cat(list(mlp_out_cache.values()), dim=0)\n",
    "print(mlp_in_cache.device, mlp_in_cache.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab63b8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 8, 768])\n"
     ]
    }
   ],
   "source": [
    "nnsight_acts = []\n",
    "with llm.trace(tokens) as trace:\n",
    "    for layer in range(12):\n",
    "        layer_activations = llm.transformer.h[layer].ln_2.input.save()\n",
    "        nnsight_acts.append(layer_activations.squeeze(0))\n",
    "\n",
    "nnsight_acts = torch.stack(nnsight_acts, dim=0)\n",
    "\n",
    "print(nnsight_acts.shape)\n",
    "nnsight_acts = nnsight_acts.to(\"cuda:0\").to(torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ef9ad21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 torch.bfloat16\n"
     ]
    }
   ],
   "source": [
    "mlp_in_cache = mlp_in_cache.to(\"cuda:0\").to(torch.bfloat16)\n",
    "print(mlp_in_cache.device, mlp_in_cache.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d9f797e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 768]) torch.Size([8, 768])\n",
      "cuda:0 cuda:0\n",
      "torch.bfloat16 torch.bfloat16\n",
      "nans?: False, False\n",
      "max diff: 0.001953125\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([8, 768]) torch.Size([8, 768])\n",
      "cuda:0 cuda:0\n",
      "torch.bfloat16 torch.bfloat16\n",
      "nans?: False, False\n",
      "max diff: 0.000244140625\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([8, 768]) torch.Size([8, 768])\n",
      "cuda:0 cuda:0\n",
      "torch.bfloat16 torch.bfloat16\n",
      "nans?: False, False\n",
      "max diff: 0.0009765625\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([8, 768]) torch.Size([8, 768])\n",
      "cuda:0 cuda:0\n",
      "torch.bfloat16 torch.bfloat16\n",
      "nans?: False, False\n",
      "max diff: 0.0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([8, 768]) torch.Size([8, 768])\n",
      "cuda:0 cuda:0\n",
      "torch.bfloat16 torch.bfloat16\n",
      "nans?: False, False\n",
      "max diff: 0.015625\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([8, 768]) torch.Size([8, 768])\n",
      "cuda:0 cuda:0\n",
      "torch.bfloat16 torch.bfloat16\n",
      "nans?: False, False\n",
      "max diff: 0.015625\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([8, 768]) torch.Size([8, 768])\n",
      "cuda:0 cuda:0\n",
      "torch.bfloat16 torch.bfloat16\n",
      "nans?: False, False\n",
      "max diff: 0.00048828125\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([8, 768]) torch.Size([8, 768])\n",
      "cuda:0 cuda:0\n",
      "torch.bfloat16 torch.bfloat16\n",
      "nans?: False, False\n",
      "max diff: 0.0078125\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([8, 768]) torch.Size([8, 768])\n",
      "cuda:0 cuda:0\n",
      "torch.bfloat16 torch.bfloat16\n",
      "nans?: False, False\n",
      "max diff: 0.0078125\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([8, 768]) torch.Size([8, 768])\n",
      "cuda:0 cuda:0\n",
      "torch.bfloat16 torch.bfloat16\n",
      "nans?: False, False\n",
      "max diff: 0.015625\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([8, 768]) torch.Size([8, 768])\n",
      "cuda:0 cuda:0\n",
      "torch.bfloat16 torch.bfloat16\n",
      "nans?: False, False\n",
      "max diff: 0.015625\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([8, 768]) torch.Size([8, 768])\n",
      "cuda:0 cuda:0\n",
      "torch.bfloat16 torch.bfloat16\n",
      "nans?: False, False\n",
      "max diff: 0.015625\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "## TEST Difference between nnsight and TL activations\n",
    "for i in range(12):\n",
    "    print(nnsight_acts[i].shape, mlp_in_cache[i].shape)\n",
    "    print(nnsight_acts[i].device, mlp_in_cache[i].device)\n",
    "    print(nnsight_acts[i].dtype, mlp_in_cache[i].dtype)\n",
    "    print(f\"nans?: {torch.isnan(nnsight_acts[i]).any()}, {torch.isnan(mlp_in_cache[i]).any()}\")\n",
    "    print(f\"max diff: {(nnsight_acts[i] - mlp_in_cache[i]).abs().max().item()}\")\n",
    "    print(\"-\"*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3187e1a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 8, 768]) cuda:0 torch.bfloat16\n",
      "torch.Size([12, 8, 768]) cuda:0 torch.bfloat16\n",
      "layer 0 nnz: 467\n",
      "layer 1 nnz: 241\n",
      "layer 2 nnz: 130\n",
      "layer 3 nnz: 108\n",
      "layer 4 nnz: 107\n",
      "layer 5 nnz: 66\n",
      "layer 6 nnz: 88\n",
      "layer 7 nnz: 42\n",
      "layer 8 nnz: 31\n",
      "layer 9 nnz: 18\n",
      "layer 10 nnz: 12\n",
      "layer 11 nnz: 1\n",
      "nnz features: 1311\n",
      "torch.Size([12, 8, 10000])\n",
      "layer 0 nnz: 467\n",
      "layer 1 nnz: 241\n",
      "layer 2 nnz: 130\n",
      "layer 3 nnz: 108\n",
      "layer 4 nnz: 107\n",
      "layer 5 nnz: 66\n",
      "layer 6 nnz: 88\n",
      "layer 7 nnz: 42\n",
      "layer 8 nnz: 31\n",
      "layer 9 nnz: 18\n",
      "layer 10 nnz: 12\n",
      "layer 11 nnz: 1\n",
      "nnz features: 1311\n",
      "torch.Size([12, 8, 10000])\n"
     ]
    }
   ],
   "source": [
    "print(nnsight_acts.shape, nnsight_acts.device, nnsight_acts.dtype)\n",
    "print(mlp_in_cache.shape, mlp_in_cache.device, mlp_in_cache.dtype)\n",
    "attribution_data_a = circuit_tracer_transcoder.compute_attribution_components(nnsight_acts)\n",
    "attribution_data_c = circuit_tracer_transcoder.compute_attribution_components(mlp_in_cache)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e4d00ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 torch.float32\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type BFloat16 but found Float",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(circuit_tracer_transcoder_copy.device, circuit_tracer_transcoder_copy.dtype)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m attribution_data_e = \u001b[43mcircuit_tracer_transcoder_copy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompute_attribution_components\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmlp_in_cache\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m attribution_data_e = circuit_tracer_transcoder_copy.compute_attribution_components(in_acts_clt)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/circuit-tracer/circuit_tracer/transcoder/cross_layer_transcoder.py:306\u001b[39m, in \u001b[36mCrossLayerTranscoder.compute_attribution_components\u001b[39m\u001b[34m(self, inputs)\u001b[39m\n\u001b[32m    292\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_attribution_components\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs):\n\u001b[32m    293\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Extract active features and their encoder/decoder vectors for attribution.\u001b[39;00m\n\u001b[32m    294\u001b[39m \n\u001b[32m    295\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    304\u001b[39m \u001b[33;03m            - encoder_to_decoder_map: Mapping from encoder to decoder indices\u001b[39;00m\n\u001b[32m    305\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m306\u001b[39m     features, encoder_vectors = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencode_sparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzero_first_pos\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    307\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mnnz features: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeatures._nnz()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    308\u001b[39m     pos_ids, layer_ids, feat_ids, decoder_vectors, encoder_to_decoder_map = (\n\u001b[32m    309\u001b[39m         \u001b[38;5;28mself\u001b[39m.select_decoder_vectors(features)\n\u001b[32m    310\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/circuit-tracer/circuit_tracer/transcoder/cross_layer_transcoder.py:193\u001b[39m, in \u001b[36mCrossLayerTranscoder.encode_sparse\u001b[39m\u001b[34m(self, x, zero_first_pos)\u001b[39m\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.n_layers):\n\u001b[32m    191\u001b[39m     W_enc_layer = \u001b[38;5;28mself\u001b[39m._get_encoder_weights(layer_id)\n\u001b[32m    192\u001b[39m     layer_features = (\n\u001b[32m--> \u001b[39m\u001b[32m193\u001b[39m         \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbd,fd->bf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW_enc_layer\u001b[49m\u001b[43m)\u001b[49m + \u001b[38;5;28mself\u001b[39m.b_enc[layer_id]\n\u001b[32m    194\u001b[39m     )\n\u001b[32m    195\u001b[39m     layer_features = \u001b[38;5;28mself\u001b[39m.apply_activation_function(layer_id, layer_features)\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m zero_first_pos:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/crosslayer-transcoder/.venv/lib/python3.12/site-packages/torch/functional.py:373\u001b[39m, in \u001b[36meinsum\u001b[39m\u001b[34m(*args)\u001b[39m\n\u001b[32m    368\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m einsum(equation, *_operands)\n\u001b[32m    370\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(operands) <= \u001b[32m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_einsum.enabled:\n\u001b[32m    371\u001b[39m     \u001b[38;5;66;03m# the path for contracting 0 or 1 time(s) is already optimized\u001b[39;00m\n\u001b[32m    372\u001b[39m     \u001b[38;5;66;03m# or the user has disabled using opt_einsum\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m373\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[43m.\u001b[49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mequation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperands\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m    375\u001b[39m path = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    376\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m opt_einsum.is_available():\n",
      "\u001b[31mRuntimeError\u001b[39m: expected scalar type BFloat16 but found Float"
     ]
    }
   ],
   "source": [
    "print(circuit_tracer_transcoder_copy.device, circuit_tracer_transcoder_copy.dtype)\n",
    "attribution_data_e = circuit_tracer_transcoder_copy.compute_attribution_components(mlp_in_cache)\n",
    "attribution_data_e = circuit_tracer_transcoder_copy.compute_attribution_components(in_acts_clt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48295bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "attribution_data = rm.transcoders.compute_attribution_components(mlp_in_cache)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4983b9eb",
   "metadata": {},
   "source": [
    "### Attribution test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9ea5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_n_logits = 10  # How many logits to attribute from, max. We attribute to min(max_n_logits, n_logits_to_reach_desired_log_prob); see below for the latter\n",
    "desired_logit_prob = 0.95  # Attribution will attribute from the minimum number of logits needed to reach this probability mass (or max_n_logits, whichever is lower)\n",
    "max_feature_nodes = 100  # Only attribute from this number of feature nodes, max. Lower is faster, but you will lose more of the graph. None means no limit.\n",
    "batch_size = 256 // 8  # Batch size when attributing\n",
    "offload = \"cpu\"  # Offload various parts of the model during attribution to save memory. Can be 'disk', 'cpu', or None (keep on GPU)\n",
    "verbose = True  # Whether to display a tqdm progress bar and timing report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c54601",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "from circuit_tracer import ReplacementModel, attribute\n",
    "from circuit_tracer.utils import create_graph_files\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# FOr some reason this takes up a lot of VRAM\n",
    "graph = attribute(\n",
    "    prompt=prompt,\n",
    "    model=rm,\n",
    "    max_n_logits=max_n_logits,\n",
    "    desired_logit_prob=desired_logit_prob,\n",
    "    batch_size=batch_size,\n",
    "    max_feature_nodes=max_feature_nodes,\n",
    "    offload=offload,\n",
    "    verbose=verbose,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c454ee0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
