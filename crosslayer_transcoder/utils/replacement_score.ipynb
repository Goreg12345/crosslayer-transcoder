{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dc2a0d5",
   "metadata": {},
   "source": [
    "# Replacement Score Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b90bb04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crosslayer_transcoder.utils.model_converters.circuit_tracer import (\n",
    "    CircuitTracerConverter,\n",
    ")\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a091f9ee",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a37586eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DTYPE = torch.bfloat16\n",
    "checkpoint = \"../checkpoints/clt.ckpt\"\n",
    "config_path = \"../../config/circuit-tracer.yaml\"\n",
    "identifier = \"gpt2-crosslayer-clt-v1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4458999",
   "metadata": {},
   "source": [
    "### Load model from local checkpoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c166ce94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9143e88a119645a5b1e1857fbb6893e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1217 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1561 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2459 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1174 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2027 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "from crosslayer_transcoder.utils.module_builder import build_module_from_config, yaml_to_config\n",
    "from crosslayer_transcoder.utils.checkpoints import load_model_from_lightning_checkpoint\n",
    "\n",
    "config = yaml_to_config(config_path)\n",
    "clt_module = build_module_from_config(config)\n",
    "clt_module = load_model_from_lightning_checkpoint(clt_module, checkpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f259397a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting CLT : 100%|██████████| 12/12 [00:23<00:00,  1.99s/it]\n"
     ]
    }
   ],
   "source": [
    "save_dir = \"clt_module_test\"\n",
    "feature_input_hook = \"hook_resid_mid\"\n",
    "feature_output_hook = \"hook_mlp_out\"\n",
    "\n",
    "converter = CircuitTracerConverter(\n",
    "save_dir=save_dir,\n",
    "feature_input_hook=feature_input_hook,\n",
    "    feature_output_hook=feature_output_hook,\n",
    ")\n",
    "converter.convert_and_save(clt_module, dtype=DTYPE) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae50d526",
   "metadata": {},
   "source": [
    "### Load model from local converted checkpoint\n",
    "\n",
    "In the future, this could be loaded from huggingface using the `ReplacementModel.from_pretrained`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8d8594b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from circuit_tracer.transcoder.cross_layer_transcoder import load_clt\n",
    "circuit_tracer_clt = load_clt(\n",
    "    clt_path=save_dir,\n",
    "    lazy_decoder=False,\n",
    "    lazy_encoder=False,\n",
    "    feature_input_hook=feature_input_hook,\n",
    "    feature_output_hook=feature_output_hook,\n",
    "    dtype=DTYPE,\n",
    "    scan=identifier\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bcce2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2 into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "from circuit_tracer import ReplacementModel\n",
    "\n",
    "rm = ReplacementModel.from_pretrained_and_transcoders(\n",
    "    \"gpt2\",\n",
    "    circuit_tracer_clt,\n",
    "    dtype=DTYPE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8448dc8b",
   "metadata": {},
   "source": [
    "### Attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10269291",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = (\n",
    "    \"The capital of state containing Dallas is\"  # What you want to get the graph for\n",
    ")\n",
    "max_n_logits = 10  # How many logits to attribute from, max. We attribute to min(max_n_logits, n_logits_to_reach_desired_log_prob); see below for the latter\n",
    "desired_logit_prob = 0.95  # Attribution will attribute from the minimum number of logits needed to reach this probability mass (or max_n_logits, whichever is lower)\n",
    "max_feature_nodes = 8192  # Only attribute from this number of feature nodes, max. Lower is faster, but you will lose more of the graph. None means no limit.\n",
    "batch_size = 256  # Batch size when attributing\n",
    "verbose = True  # Whether to display a tqdm progress bar and timing report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecb6f82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Phase 0: Precomputing activations and vectors\n",
      "Precomputation completed in 0.51s\n",
      "Found 1316 active features\n",
      "Phase 1: Running forward pass\n",
      "Forward pass completed in 0.04s\n",
      "Phase 2: Building input vectors\n",
      "Selected 10 logits with cumulative probability 0.2871\n",
      "Will include 1316 of 1316 feature nodes\n",
      "Input vectors built in 0.04s\n",
      "Phase 3: Computing logit attributions\n",
      "sys:1: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.\n",
      "Logit attributions completed in 0.05s\n",
      "Phase 4: Computing feature attributions\n",
      "Feature influence computation: 100%|██████████| 1316/1316 [00:00<00:00, 7560.45it/s]\n",
      "Feature attributions completed in 0.18s\n",
      "Attribution completed in 0.82s\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "from circuit_tracer import attribute\n",
    "from circuit_tracer.utils import create_graph_files\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "graph = attribute(\n",
    "    prompt=prompt,\n",
    "    model=rm,\n",
    "    max_n_logits=max_n_logits,\n",
    "    desired_logit_prob=desired_logit_prob,\n",
    "    batch_size=batch_size,\n",
    "    max_feature_nodes=max_feature_nodes,\n",
    "    offload=None,\n",
    "    verbose=verbose\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fa0b05",
   "metadata": {},
   "source": [
    "### Replacement Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4008f230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7424161434173584, 0.919729471206665)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from circuit_tracer.graph import compute_graph_scores\n",
    "print(\"replacement score, completeness score\")\n",
    "compute_graph_scores(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33c5e46",
   "metadata": {},
   "source": [
    "### Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "191aafa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_dir = 'graphs'\n",
    "graph_name = 'example_graph.pt'\n",
    "graph_dir = Path(graph_dir)\n",
    "graph_dir.mkdir(exist_ok=True)\n",
    "graph_path = graph_dir / graph_name\n",
    "\n",
    "graph.to_pt(graph_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e4da199",
   "metadata": {},
   "outputs": [],
   "source": [
    "slug = \"dallas-austin\"  # this is the name that you assign to the graph\n",
    "graph_file_dir = \"./graph_files\"  # where to write the graph files. no need to make this one; create_graph_files does that for you\n",
    "node_threshold = (\n",
    "    0.8  # keep only the minimum # of nodes whose cumulative influence is >= 0.8\n",
    ")\n",
    "edge_threshold = (\n",
    "    0.98  # keep only the minimum # of edges whose cumulative influence is >= 0.98\n",
    ")\n",
    "\n",
    "create_graph_files(\n",
    "    graph_or_path=graph_path,  # the graph to create files for\n",
    "    slug=slug,\n",
    "    output_path=graph_file_dir,\n",
    "    node_threshold=node_threshold,\n",
    "    edge_threshold=edge_threshold,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50185332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use the IFrame below, or open your graph here: f'http://localhost:8046/index.html'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800px\"\n",
       "            src=\"http://localhost:8046/index.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x717032c2b830>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from circuit_tracer.frontend.local_server import serve\n",
    "from IPython.display import IFrame\n",
    "\n",
    "port = 8046\n",
    "server = serve(data_dir=\"./graph_files/\", port=port)\n",
    "\n",
    "\n",
    "print(\n",
    "    f\"Use the IFrame below, or open your graph here: f'http://localhost:{port}/index.html'\"\n",
    ")\n",
    "display(\n",
    "    IFrame(src=f\"http://localhost:{port}/index.html\", width=\"100%\", height=\"800px\")\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
