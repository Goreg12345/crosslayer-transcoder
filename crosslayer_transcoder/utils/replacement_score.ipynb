{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dc2a0d5",
   "metadata": {},
   "source": [
    "# Replacement Score Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19aa81f",
   "metadata": {},
   "source": [
    "## Load the model from the local checkpoint (save from HF before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b90bb04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import shutil\n",
    "from circuit_tracer.transcoder.cross_layer_transcoder import load_clt\n",
    "\n",
    "from crosslayer_transcoder.utils.model_converters.circuit_tracer import (\n",
    "    CircuitTracerConverter,\n",
    ")\n",
    "from transformer_lens import HookedTransformerConfig\n",
    "from transformer_lens.loading_from_pretrained import get_pretrained_model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4ddba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_TOKEN\"] = \"ADD_TOKEN_HERE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c166ce94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model {'class_path': 'crosslayer_transcoder.model.clt.CrossLayerTranscoder', 'init_args': {'encoder': {'class_path': 'crosslayer_transcoder.model.clt.Encoder', 'init_args': {'d_acts': 768, 'd_features': 10000, 'n_layers': 12}}, 'decoder': {'class_path': 'crosslayer_transcoder.model.clt.CrosslayerDecoder', 'init_args': {'d_acts': 768, 'd_features': 10000, 'n_layers': 12}}, 'nonlinearity': {'class_path': 'crosslayer_transcoder.model.topk.PerLayerTopK', 'init_args': {'k': 16}}, 'input_standardizer': {'class_path': 'crosslayer_transcoder.model.standardize.DimensionwiseInputStandardizer', 'init_args': {'n_layers': 12, 'activation_dim': 768}}, 'output_standardizer': {'class_path': 'crosslayer_transcoder.model.standardize.DimensionwiseOutputStandardizer', 'init_args': {'n_layers': 12, 'activation_dim': 768}}}}\n",
      "encoder {'class_path': 'crosslayer_transcoder.model.clt.Encoder', 'init_args': {'d_acts': 768, 'd_features': 10000, 'n_layers': 12}}\n",
      "d_acts 768\n",
      "d_features 10000\n",
      "n_layers 12\n",
      "decoder {'class_path': 'crosslayer_transcoder.model.clt.CrosslayerDecoder', 'init_args': {'d_acts': 768, 'd_features': 10000, 'n_layers': 12}}\n",
      "d_acts 768\n",
      "d_features 10000\n",
      "n_layers 12\n",
      "nonlinearity {'class_path': 'crosslayer_transcoder.model.topk.PerLayerTopK', 'init_args': {'k': 16}}\n",
      "k 16\n",
      "input_standardizer {'class_path': 'crosslayer_transcoder.model.standardize.DimensionwiseInputStandardizer', 'init_args': {'n_layers': 12, 'activation_dim': 768}}\n",
      "n_layers 12\n",
      "activation_dim 768\n",
      "output_standardizer {'class_path': 'crosslayer_transcoder.model.standardize.DimensionwiseOutputStandardizer', 'init_args': {'n_layers': 12, 'activation_dim': 768}}\n",
      "n_layers 12\n",
      "activation_dim 768\n",
      "replacement_model {'class_path': 'crosslayer_transcoder.metrics.replacement_model_accuracy.ReplacementModelAccuracy', 'init_args': {'model_name': 'openai-community/gpt2', 'device_map': 'cuda:0', 'loader_batch_size': 2}}\n",
      "model_name openai-community/gpt2\n",
      "device_map cuda:0\n",
      "loader_batch_size 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cadefb64507d4274bc276cc7bfc07cb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1217 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1174 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dead_features {'class_path': 'crosslayer_transcoder.metrics.dead_features.DeadFeatures', 'init_args': {'n_features': 10000, 'n_layers': 12, 'return_per_layer': True, 'return_log_freqs': True, 'return_neuron_indices': True}}\n",
      "n_features 10000\n",
      "n_layers 12\n",
      "return_per_layer True\n",
      "return_log_freqs True\n",
      "return_neuron_indices True\n",
      "learning_rate 3e-4\n",
      "compile True\n",
      "lr_decay_step 16000\n",
      "lr_decay_factor 0.1\n",
      "topk_aux {'class_path': 'crosslayer_transcoder.model.topk.PerLayerTopK', 'init_args': {'k': 512}}\n",
      "k 512\n",
      "tokens_till_dead 500000\n",
      "aux_loss_scale 0.03125\n",
      "compute_dead_features True\n",
      "compute_dead_features_every 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1561 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2027 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2459 > 1024). Running this sequence through the model will result in indexing errors\n",
      "/root/crosslayer-transcoder/.venv/lib/python3.12/site-packages/lightning/pytorch/utilities/parsing.py:210: Attribute 'topk_aux' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['topk_aux'])`.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from crosslayer_transcoder.utils.module_builder import build_module_from_config, yaml_to_config\n",
    "config = yaml_to_config(\"../../config/topk-clt-debug.yaml\")\n",
    "clt_module = build_module_from_config(config)\n",
    "\n",
    "save_dir = pathlib.Path(\"clt_module_test\")\n",
    "feature_input_hook = \"hook_resid_pre\"\n",
    "feature_output_hook = \"hook_mlp_out\"\n",
    "\n",
    "converter = CircuitTracerConverter(\n",
    "save_dir=save_dir,\n",
    "feature_input_hook=feature_input_hook,\n",
    "    feature_output_hook=feature_output_hook,\n",
    ")\n",
    "converter.convert_and_save(clt_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8d8594b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcoder = load_clt(\n",
    "    clt_path=save_dir.as_posix(),\n",
    "    lazy_decoder=False,\n",
    "    lazy_encoder=False,\n",
    "    feature_input_hook=feature_input_hook,\n",
    "    feature_output_hook=feature_output_hook,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bcce2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "config = get_pretrained_model_config(\"gpt2\")\n",
    "config.d_type = torch.float16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3f41040",
   "metadata": {},
   "outputs": [],
   "source": [
    "from circuit_tracer import ReplacementModel\n",
    "rm = ReplacementModel.from_config(\n",
    "    config=config,\n",
    "    transcoders=transcoder,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10269291",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = (\n",
    "    \"The capital of state containing Dallas is\"  # What you want to get the graph for\n",
    ")\n",
    "max_n_logits = 10  # How many logits to attribute from, max. We attribute to min(max_n_logits, n_logits_to_reach_desired_log_prob); see below for the latter\n",
    "desired_logit_prob = 0.95  # Attribution will attribute from the minimum number of logits needed to reach this probability mass (or max_n_logits, whichever is lower)\n",
    "max_feature_nodes = 8192  # Only attribute from this number of feature nodes, max. Lower is faster, but you will lose more of the graph. None means no limit.\n",
    "batch_size = 256  # Batch size when attributing\n",
    "offload = (\n",
    "    \"cpu\"\n",
    ")  # Offload various parts of the model during attribution to save memory. Can be 'disk', 'cpu', or None (keep on GPU)\n",
    "verbose = True  # Whether to display a tqdm progress bar and timing report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecb6f82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Phase 0: Precomputing activations and vectors\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 15.62 GiB. GPU 0 has a total capacity of 31.37 GiB of which 7.31 GiB is free. Including non-PyTorch memory, this process has 24.05 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 1.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m torch.cuda.empty_cache()\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# FOr some reason this takes up a lot of VRAM\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m graph = \u001b[43mattribute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_n_logits\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_n_logits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdesired_logit_prob\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdesired_logit_prob\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_feature_nodes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_feature_nodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43moffload\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/crosslayer-transcoder/.venv/lib/python3.12/site-packages/circuit_tracer/attribution/attribute.py:137\u001b[39m, in \u001b[36mattribute\u001b[39m\u001b[34m(prompt, model, max_n_logits, desired_logit_prob, batch_size, max_feature_nodes, offload, verbose, update_interval)\u001b[39m\n\u001b[32m    135\u001b[39m offload_handles = []\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_run_attribution\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_n_logits\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_n_logits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdesired_logit_prob\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdesired_logit_prob\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_feature_nodes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_feature_nodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m        \u001b[49m\u001b[43moffload\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[43m        \u001b[49m\u001b[43moffload_handles\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffload_handles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[43m        \u001b[49m\u001b[43mupdate_interval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mupdate_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    151\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m reload_handle \u001b[38;5;129;01min\u001b[39;00m offload_handles:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/crosslayer-transcoder/.venv/lib/python3.12/site-packages/circuit_tracer/attribution/attribute.py:177\u001b[39m, in \u001b[36m_run_attribution\u001b[39m\u001b[34m(model, prompt, max_n_logits, desired_logit_prob, batch_size, max_feature_nodes, offload, verbose, offload_handles, logger, update_interval)\u001b[39m\n\u001b[32m    174\u001b[39m phase_start = time.time()\n\u001b[32m    175\u001b[39m input_ids = model.ensure_tokenized(prompt)\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m ctx = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43msetup_attribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m activation_matrix = ctx.activation_matrix\n\u001b[32m    180\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPrecomputation completed in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime.time()\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39mphase_start\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33ms\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/crosslayer-transcoder/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/crosslayer-transcoder/.venv/lib/python3.12/site-packages/circuit_tracer/replacement_model.py:433\u001b[39m, in \u001b[36mReplacementModel.setup_attribution\u001b[39m\u001b[34m(self, inputs)\u001b[39m\n\u001b[32m    430\u001b[39m mlp_in_cache = torch.cat(\u001b[38;5;28mlist\u001b[39m(mlp_in_cache.values()), dim=\u001b[32m0\u001b[39m)\n\u001b[32m    431\u001b[39m mlp_out_cache = torch.cat(\u001b[38;5;28mlist\u001b[39m(mlp_out_cache.values()), dim=\u001b[32m0\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m433\u001b[39m attribution_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtranscoders\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompute_attribution_components\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmlp_in_cache\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[38;5;66;03m# Compute error vectors\u001b[39;00m\n\u001b[32m    436\u001b[39m error_vectors = mlp_out_cache - attribution_data[\u001b[33m\"\u001b[39m\u001b[33mreconstruction\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/crosslayer-transcoder/.venv/lib/python3.12/site-packages/circuit_tracer/transcoder/cross_layer_transcoder.py:300\u001b[39m, in \u001b[36mCrossLayerTranscoder.compute_attribution_components\u001b[39m\u001b[34m(self, inputs)\u001b[39m\n\u001b[32m    285\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Extract active features and their encoder/decoder vectors for attribution.\u001b[39;00m\n\u001b[32m    286\u001b[39m \n\u001b[32m    287\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    296\u001b[39m \u001b[33;03m        - encoder_to_decoder_map: Mapping from encoder to decoder indices\u001b[39;00m\n\u001b[32m    297\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    298\u001b[39m features, encoder_vectors = \u001b[38;5;28mself\u001b[39m.encode_sparse(inputs, zero_first_pos=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    299\u001b[39m pos_ids, layer_ids, feat_ids, decoder_vectors, encoder_to_decoder_map = (\n\u001b[32m--> \u001b[39m\u001b[32m300\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mselect_decoder_vectors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    301\u001b[39m )\n\u001b[32m    302\u001b[39m reconstruction = \u001b[38;5;28mself\u001b[39m.compute_reconstruction(pos_ids, layer_ids, decoder_vectors)\n\u001b[32m    304\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m    305\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mactivation_matrix\u001b[39m\u001b[33m\"\u001b[39m: features,\n\u001b[32m    306\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreconstruction\u001b[39m\u001b[33m\"\u001b[39m: reconstruction,\n\u001b[32m   (...)\u001b[39m\u001b[32m    310\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdecoder_locations\u001b[39m\u001b[33m\"\u001b[39m: torch.stack((layer_ids, pos_ids)),\n\u001b[32m    311\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/crosslayer-transcoder/.venv/lib/python3.12/site-packages/circuit_tracer/transcoder/cross_layer_transcoder.py:260\u001b[39m, in \u001b[36mCrossLayerTranscoder.select_decoder_vectors\u001b[39m\u001b[34m(self, features)\u001b[39m\n\u001b[32m    258\u001b[39m layer_ids = torch.cat(layer_ids, dim=\u001b[32m0\u001b[39m)\n\u001b[32m    259\u001b[39m feat_ids = torch.cat(feat_ids, dim=\u001b[32m0\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m260\u001b[39m decoder_vectors = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoder_vectors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    261\u001b[39m encoder_mapping = torch.cat(encoder_mapping, dim=\u001b[32m0\u001b[39m)\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m pos_ids, layer_ids, feat_ids, decoder_vectors, encoder_mapping\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 15.62 GiB. GPU 0 has a total capacity of 31.37 GiB of which 7.31 GiB is free. Including non-PyTorch memory, this process has 24.05 GiB memory in use. Of the allocated memory 21.92 GiB is allocated by PyTorch, and 1.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "from circuit_tracer import ReplacementModel, attribute\n",
    "from circuit_tracer.utils import create_graph_files\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# FOr some reason this takes up a lot of VRAM\n",
    "graph = attribute(\n",
    "    prompt=prompt,\n",
    "    model=rm,\n",
    "    max_n_logits=max_n_logits,\n",
    "    desired_logit_prob=desired_logit_prob,\n",
    "    batch_size=batch_size,\n",
    "    max_feature_nodes=max_feature_nodes,\n",
    "    offload=offload,\n",
    "    verbose=verbose\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191aafa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_dir = 'graphs'\n",
    "graph_name = 'example_graph.pt'\n",
    "graph_dir = Path(graph_dir)\n",
    "graph_dir.mkdir(exist_ok=True)\n",
    "graph_path = graph_dir / graph_name\n",
    "\n",
    "graph.to_pt(graph_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
