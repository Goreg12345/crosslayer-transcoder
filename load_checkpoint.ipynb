{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Load CrossLayer Transcoder from Checkpoint\n",
        "\n",
        "This notebook demonstrates how to load a saved CrossLayerTranscoderModule from a Lightning checkpoint and explore the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/metrics/g/crosslayer-transcoder/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import lightning as L\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "from model.clt_lightning import CrossLayerTranscoderModule\n",
        "from model.clt import CrossLayerTranscoder\n",
        "from model.standardize import DimensionwiseInputStandardizer, DimensionwiseOutputStandardizer\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python path:\n",
            "  /var/metrics/g/py312/lib/python312.zip\n",
            "  /var/metrics/g/py312/lib/python3.12\n",
            "  /var/metrics/g/py312/lib/python3.12/lib-dynload\n",
            "  \n",
            "  /var/metrics/g/crosslayer-transcoder/.venv/lib/python3.12/site-packages\n",
            "  /tmp/tmpg5ybyjqo\n",
            "  /var/metrics/g/crosslayer-transcoder\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "# Add current directory to Python path\n",
        "sys.path.append(os.getcwd())\n",
        "\n",
        "print(\"Python path:\")\n",
        "for path in sys.path:\n",
        "    print(f\"  {path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Load the Checkpoint\n",
        "\n",
        "Load the saved CrossLayerTranscoderModule from the Lightning checkpoint.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "usage: cli.py [-h] [-c CONFIG] [--print_config[=flags]]\n",
            "              [--seed_everything SEED_EVERYTHING] [--trainer CONFIG]\n",
            "              [--trainer.accelerator.help CLASS_PATH_OR_NAME]\n",
            "              [--trainer.accelerator ACCELERATOR]\n",
            "              [--trainer.strategy.help CLASS_PATH_OR_NAME]\n",
            "              [--trainer.strategy STRATEGY] [--trainer.devices DEVICES]\n",
            "              [--trainer.num_nodes NUM_NODES] [--trainer.precision PRECISION]\n",
            "              [--trainer.logger.help CLASS_PATH_OR_NAME]\n",
            "              [--trainer.logger LOGGER]\n",
            "              [--trainer.callbacks.help CLASS_PATH_OR_NAME]\n",
            "              [--trainer.callbacks CALLBACKS]\n",
            "              [--trainer.fast_dev_run FAST_DEV_RUN]\n",
            "              [--trainer.max_epochs MAX_EPOCHS]\n",
            "              [--trainer.min_epochs MIN_EPOCHS]\n",
            "              [--trainer.max_steps MAX_STEPS] [--trainer.min_steps MIN_STEPS]\n",
            "              [--trainer.max_time MAX_TIME]\n",
            "              [--trainer.limit_train_batches LIMIT_TRAIN_BATCHES]\n",
            "              [--trainer.limit_val_batches LIMIT_VAL_BATCHES]\n",
            "              [--trainer.limit_test_batches LIMIT_TEST_BATCHES]\n",
            "              [--trainer.limit_predict_batches LIMIT_PREDICT_BATCHES]\n",
            "              [--trainer.overfit_batches OVERFIT_BATCHES]\n",
            "              [--trainer.val_check_interval VAL_CHECK_INTERVAL]\n",
            "              [--trainer.check_val_every_n_epoch CHECK_VAL_EVERY_N_EPOCH]\n",
            "              [--trainer.num_sanity_val_steps NUM_SANITY_VAL_STEPS]\n",
            "              [--trainer.log_every_n_steps LOG_EVERY_N_STEPS]\n",
            "              [--trainer.enable_checkpointing {true,false,null}]\n",
            "              [--trainer.enable_progress_bar {true,false,null}]\n",
            "              [--trainer.enable_model_summary {true,false,null}]\n",
            "              [--trainer.accumulate_grad_batches ACCUMULATE_GRAD_BATCHES]\n",
            "              [--trainer.gradient_clip_val GRADIENT_CLIP_VAL]\n",
            "              [--trainer.gradient_clip_algorithm GRADIENT_CLIP_ALGORITHM]\n",
            "              [--trainer.deterministic DETERMINISTIC]\n",
            "              [--trainer.benchmark {true,false,null}]\n",
            "              [--trainer.inference_mode {true,false}]\n",
            "              [--trainer.use_distributed_sampler {true,false}]\n",
            "              [--trainer.profiler.help CLASS_PATH_OR_NAME]\n",
            "              [--trainer.profiler PROFILER]\n",
            "              [--trainer.detect_anomaly {true,false}]\n",
            "              [--trainer.barebones {true,false}]\n",
            "              [--trainer.plugins.help CLASS_PATH_OR_NAME]\n",
            "              [--trainer.plugins PLUGINS]\n",
            "              [--trainer.sync_batchnorm {true,false}]\n",
            "              [--trainer.reload_dataloaders_every_n_epochs RELOAD_DATALOADERS_EVERY_N_EPOCHS]\n",
            "              [--trainer.default_root_dir DEFAULT_ROOT_DIR]\n",
            "              [--trainer.model_registry MODEL_REGISTRY]\n",
            "              [--model.help [CLASS_PATH_OR_NAME]]\n",
            "              --model CONFIG | CLASS_PATH_OR_NAME | .INIT_ARG_NAME VALUE\n",
            "              [--data.help [CLASS_PATH_OR_NAME]]\n",
            "              --data CONFIG | CLASS_PATH_OR_NAME | .INIT_ARG_NAME VALUE\n",
            "              [--optimizer.help [CLASS_PATH_OR_NAME]]\n",
            "              [--optimizer CONFIG | CLASS_PATH_OR_NAME | .INIT_ARG_NAME VALUE]\n",
            "              [--lr_scheduler.help CLASS_PATH_OR_NAME]\n",
            "              [--lr_scheduler CONFIG | CLASS_PATH_OR_NAME | .INIT_ARG_NAME VALUE]\n",
            "error: Unrecognized arguments: fit --ckpt_path checkpoints/clt.ckpt\n"
          ]
        },
        {
          "ename": "SystemExit",
          "evalue": "2",
          "output_type": "error",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 2\n"
          ]
        }
      ],
      "source": [
        "# predict_loader.py\n",
        "from cli import CrossLayerTranscoderCLI\n",
        "import sys\n",
        "\n",
        "def get_model_for_inference(checkpoint_path: str, config_path: str = \"config/default.yaml\"):\n",
        "    \"\"\"\n",
        "    Use CLI predict mode to load model, then extract it.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Set up args for prediction mode\n",
        "    sys.argv = [\n",
        "        \"cli.py\", \n",
        "        \"fit\",\n",
        "        \"--config\", config_path,\n",
        "        \"--ckpt_path\", checkpoint_path,\n",
        "        \"--trainer.logger\", \"false\"\n",
        "    ]\n",
        "    \n",
        "    # Create CLI and let it load the checkpoint\n",
        "    cli = CrossLayerTranscoderCLI(\n",
        "        model_class=L.LightningModule,\n",
        "        datamodule_class=L.LightningDataModule,\n",
        "        subclass_mode_model=True,\n",
        "        subclass_mode_data=True,\n",
        "        run=False  # Don't actually run prediction\n",
        "    )\n",
        "    \n",
        "    return cli.model\n",
        "\n",
        "model = get_model_for_inference(\"checkpoints/clt.ckpt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1217 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1174 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2027 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2459 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1561 > 1024). Running this sequence through the model will result in indexing errors\n",
            "/var/metrics/g/crosslayer-transcoder/.venv/lib/python3.12/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
            "/var/metrics/g/crosslayer-transcoder/.venv/lib/python3.12/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'replacement_model_accuracy' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['replacement_model_accuracy'])`.\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Does not validate against any of the Union subtypes\nSubtypes: [<class 'NoneType'>, <class 'model.clt_lightning.CrossLayerTranscoderModule'>]\nErrors:\n  - Expected a <class 'NoneType'>\n  - maximum recursion depth exceeded\nGiven value type: <class 'jsonargparse._namespace.Namespace'>\nGiven value: Namespace(class_path='model.CrossLayerTranscoderModule', init_args=Namespace(model=Namespace(class_path='model.CrossLayerTranscoder', init_args=Namespace(nonlinearity=Namespace(class_path='model.jumprelu.JumpReLU', init_args=Namespace(theta=0.03, bandwidth=1.0, n_layers=12, d_features=6144)), input_standardizer=Namespace(class_path='model.standardize.DimensionwiseInputStandardizer', init_args=Namespace(n_layers=12, activation_dim=768)), output_standardizer=Namespace(class_path='model.standardize.DimensionwiseOutputStandardizer', init_args=Namespace(n_layers=12, activation_dim=768)), d_acts=768, d_features=6144, n_layers=12)), lambda_sparsity=0.0004, c_sparsity=0.1, learning_rate=0.001, replacement_model_accuracy=Namespace(class_path='metrics.ReplacementModelAccuracy', init_args=Namespace(model_name='openai-community/gpt2', device_map='cuda:0', loader_batch_size=5)), compile=True))",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32m/var/metrics/g/crosslayer-transcoder/.venv/lib/python3.12/site-packages/jsonargparse/_typehints.py:840\u001b[39m, in \u001b[36madapt_typehints\u001b[39m\u001b[34m(val, typehint, serialize, instantiate_classes, prev_val, orig_val, append, list_item, enable_path, sub_add_kwargs, default, logger)\u001b[39m\n\u001b[32m    839\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m840\u001b[39m     vals.append(\u001b[43madapt_typehints\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43madapt_kwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    841\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/var/metrics/g/crosslayer-transcoder/.venv/lib/python3.12/site-packages/jsonargparse/_typehints.py:789\u001b[39m, in \u001b[36madapt_typehints\u001b[39m\u001b[34m(val, typehint, serialize, instantiate_classes, prev_val, orig_val, append, list_item, enable_path, sub_add_kwargs, default, logger)\u001b[39m\n\u001b[32m    788\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(val, typehint) \u001b[38;5;129;01mor\u001b[39;00m (typehint \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(val, \u001b[38;5;28mbool\u001b[39m)):\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m         \u001b[43mraise_unexpected_value\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mExpected a \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtypehint\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[38;5;66;03m# Annotated\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/var/metrics/g/crosslayer-transcoder/.venv/lib/python3.12/site-packages/jsonargparse/_typehints.py:711\u001b[39m, in \u001b[36mraise_unexpected_value\u001b[39m\u001b[34m(message, val, exception)\u001b[39m\n\u001b[32m    710\u001b[39m     message += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m. Got value: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m711\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexception\u001b[39;00m\n",
            "\u001b[31mValueError\u001b[39m: Expected a <class 'NoneType'>. Got value: Namespace(class_path='model.CrossLayerTranscoderModule', init_args=Namespace(model=Namespace(class_path='model.CrossLayerTranscoder', init_args=Namespace(nonlinearity=Namespace(class_path='model.jumprelu.JumpReLU', init_args=Namespace(theta=0.03, bandwidth=1.0, n_layers=12, d_features=6144)), input_standardizer=Namespace(class_path='model.standardize.DimensionwiseInputStandardizer', init_args=Namespace(n_layers=12, activation_dim=768)), output_standardizer=Namespace(class_path='model.standardize.DimensionwiseOutputStandardizer', init_args=Namespace(n_layers=12, activation_dim=768)), d_acts=768, d_features=6144, n_layers=12)), lambda_sparsity=0.0004, c_sparsity=0.1, learning_rate=0.001, replacement_model_accuracy=Namespace(class_path='metrics.ReplacementModelAccuracy', init_args=Namespace(model_name='openai-community/gpt2', device_map='cuda:0', loader_batch_size=5)), compile=True))",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Path to the checkpoint\u001b[39;00m\n\u001b[32m      2\u001b[39m checkpoint_path = \u001b[33m\"\u001b[39m\u001b[33mcheckpoints/clt.ckpt\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m model = \u001b[43mCrossLayerTranscoderModule\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcuda:1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Load to GPU 1\u001b[39;49;00m\n\u001b[32m      6\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m model.eval()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/var/metrics/g/crosslayer-transcoder/.venv/lib/python3.12/site-packages/lightning/pytorch/utilities/model_helpers.py:125\u001b[39m, in \u001b[36m_restricted_classmethod_impl.__get__.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    120\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m instance \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scripting:\n\u001b[32m    121\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    122\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe classmethod `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.method.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` cannot be called on an instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    123\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m Please call it on the class type and make sure the return value is used.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    124\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/var/metrics/g/crosslayer-transcoder/.venv/lib/python3.12/site-packages/lightning/pytorch/core/module.py:1581\u001b[39m, in \u001b[36mLightningModule.load_from_checkpoint\u001b[39m\u001b[34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[39m\n\u001b[32m   1492\u001b[39m \u001b[38;5;129m@_restricted_classmethod\u001b[39m\n\u001b[32m   1493\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_from_checkpoint\u001b[39m(\n\u001b[32m   1494\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1499\u001b[39m     **kwargs: Any,\n\u001b[32m   1500\u001b[39m ) -> Self:\n\u001b[32m   1501\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint it stores the arguments\u001b[39;00m\n\u001b[32m   1502\u001b[39m \u001b[33;03m    passed to ``__init__``  in the checkpoint under ``\"hyper_parameters\"``.\u001b[39;00m\n\u001b[32m   1503\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1579\u001b[39m \n\u001b[32m   1580\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1581\u001b[39m     loaded = \u001b[43m_load_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1582\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1583\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1584\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1585\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhparams_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1586\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1587\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1588\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1589\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(Self, loaded)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/var/metrics/g/crosslayer-transcoder/.venv/lib/python3.12/site-packages/lightning/pytorch/core/saving.py:91\u001b[39m, in \u001b[36m_load_from_checkpoint\u001b[39m\u001b[34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[39m\n\u001b[32m     89\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _load_state(\u001b[38;5;28mcls\u001b[39m, checkpoint, **kwargs)\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, pl.LightningModule):\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     model = \u001b[43m_load_state\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     92\u001b[39m     state_dict = checkpoint[\u001b[33m\"\u001b[39m\u001b[33mstate_dict\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m state_dict:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/var/metrics/g/crosslayer-transcoder/.venv/lib/python3.12/site-packages/lightning/pytorch/core/saving.py:165\u001b[39m, in \u001b[36m_load_state\u001b[39m\u001b[34m(cls, checkpoint, strict, **cls_kwargs_new)\u001b[39m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cls_spec.varkw:\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# filter kwargs according to class init unless it allows any argument via kwargs\u001b[39;00m\n\u001b[32m    163\u001b[39m     _cls_kwargs = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m _cls_kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m cls_init_args_name}\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m obj = \u001b[43minstantiator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_cls_kwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m instantiator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(**_cls_kwargs)\n\u001b[32m    167\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, pl.LightningDataModule):\n\u001b[32m    168\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m obj.\u001b[34m__class__\u001b[39m.\u001b[34m__qualname__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m checkpoint:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/var/metrics/g/crosslayer-transcoder/.venv/lib/python3.12/site-packages/lightning/pytorch/cli.py:829\u001b[39m, in \u001b[36minstantiate_module\u001b[39m\u001b[34m(class_type, config)\u001b[39m\n\u001b[32m    827\u001b[39m     parser.add_class_arguments(class_type, \u001b[33m\"\u001b[39m\u001b[33mmodule\u001b[39m\u001b[33m\"\u001b[39m, fail_untyped=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    828\u001b[39m cfg = parser.parse_object({\u001b[33m\"\u001b[39m\u001b[33mmodule\u001b[39m\u001b[33m\"\u001b[39m: config})\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m init = \u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43minstantiate_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    830\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m init.module\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/var/metrics/g/crosslayer-transcoder/.venv/lib/python3.12/site-packages/jsonargparse/_deprecated.py:147\u001b[39m, in \u001b[36mparse_as_dict_patch.<locals>.patched_instantiate_classes\u001b[39m\u001b[34m(self, cfg, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(cfg, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    146\u001b[39m     cfg = \u001b[38;5;28mself\u001b[39m._apply_actions(cfg)\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m cfg = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_unpatched_instantiate_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cfg.as_dict() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._parse_as_dict \u001b[38;5;28;01melse\u001b[39;00m cfg\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/var/metrics/g/crosslayer-transcoder/.venv/lib/python3.12/site-packages/jsonargparse/_core.py:1262\u001b[39m, in \u001b[36mArgumentParser.instantiate_classes\u001b[39m\u001b[34m(self, cfg, instantiate_groups)\u001b[39m\n\u001b[32m   1255\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1256\u001b[39m             \u001b[38;5;28;01mwith\u001b[39;00m parser_context(\n\u001b[32m   1257\u001b[39m                 parent_parser=\u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1258\u001b[39m                 nested_links=ActionLink.get_nested_links(\u001b[38;5;28mself\u001b[39m, component),\n\u001b[32m   1259\u001b[39m                 class_instantiators=\u001b[38;5;28mself\u001b[39m._get_instantiators(),\n\u001b[32m   1260\u001b[39m                 applied_instantiation_links=cfg.get(\u001b[33m\"\u001b[39m\u001b[33m__applied_instantiation_links__\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1261\u001b[39m             ):\n\u001b[32m-> \u001b[39m\u001b[32m1262\u001b[39m                 parent[key] = \u001b[43mcomponent\u001b[49m\u001b[43m.\u001b[49m\u001b[43minstantiate_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1263\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1264\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m parser_context(\n\u001b[32m   1265\u001b[39m         load_value_mode=\u001b[38;5;28mself\u001b[39m.parser_mode,\n\u001b[32m   1266\u001b[39m         class_instantiators=\u001b[38;5;28mself\u001b[39m._get_instantiators(),\n\u001b[32m   1267\u001b[39m         applied_instantiation_links=cfg.get(\u001b[33m\"\u001b[39m\u001b[33m__applied_instantiation_links__\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1268\u001b[39m     ):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/var/metrics/g/crosslayer-transcoder/.venv/lib/python3.12/site-packages/jsonargparse/_typehints.py:618\u001b[39m, in \u001b[36mActionTypeHint.instantiate_classes\u001b[39m\u001b[34m(self, value)\u001b[39m\n\u001b[32m    616\u001b[39m sub_add_kwargs = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msub_add_kwargs\u001b[39m\u001b[33m\"\u001b[39m, {})\n\u001b[32m    617\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m num, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(value):\n\u001b[32m--> \u001b[39m\u001b[32m618\u001b[39m     value[num] = \u001b[43madapt_typehints\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    619\u001b[39m \u001b[43m        \u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    620\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_typehint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    621\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdefault\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdefault\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[43m        \u001b[49m\u001b[43minstantiate_classes\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    623\u001b[39m \u001b[43m        \u001b[49m\u001b[43msub_add_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43msub_add_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    624\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    625\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m value \u001b[38;5;28;01mif\u001b[39;00m islist \u001b[38;5;28;01melse\u001b[39;00m value[\u001b[32m0\u001b[39m]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/var/metrics/g/crosslayer-transcoder/.venv/lib/python3.12/site-packages/jsonargparse/_typehints.py:848\u001b[39m, in \u001b[36madapt_typehints\u001b[39m\u001b[34m(val, typehint, serialize, instantiate_classes, prev_val, orig_val, append, list_item, enable_path, sub_add_kwargs, default, logger)\u001b[39m\n\u001b[32m    846\u001b[39m             vals.append(ex)\n\u001b[32m    847\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(v, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m vals):\n\u001b[32m--> \u001b[39m\u001b[32m848\u001b[39m         \u001b[43mraise_union_unexpected_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43msorted_subtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    849\u001b[39m     val = vals[-\u001b[32m1\u001b[39m]\n\u001b[32m    851\u001b[39m \u001b[38;5;66;03m# Tuple or Set\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/var/metrics/g/crosslayer-transcoder/.venv/lib/python3.12/site-packages/jsonargparse/_typehints.py:718\u001b[39m, in \u001b[36mraise_union_unexpected_value\u001b[39m\u001b[34m(subtypes, val, exceptions)\u001b[39m\n\u001b[32m    716\u001b[39m errors = indent_text(\u001b[33m\"\u001b[39m\u001b[33m- \u001b[39m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m- \u001b[39m\u001b[33m\"\u001b[39m.join(str_exceptions))\n\u001b[32m    717\u001b[39m errors = errors.replace(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m. Got value: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m).replace(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m718\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    719\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDoes not validate against any of the Union subtypes\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mSubtypes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubtypes\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    720\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mErrors:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00merrors\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mGiven value type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(val)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mGiven value: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    721\u001b[39m ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexceptions\u001b[39;00m[\u001b[32m0\u001b[39m]\n",
            "\u001b[31mValueError\u001b[39m: Does not validate against any of the Union subtypes\nSubtypes: [<class 'NoneType'>, <class 'model.clt_lightning.CrossLayerTranscoderModule'>]\nErrors:\n  - Expected a <class 'NoneType'>\n  - maximum recursion depth exceeded\nGiven value type: <class 'jsonargparse._namespace.Namespace'>\nGiven value: Namespace(class_path='model.CrossLayerTranscoderModule', init_args=Namespace(model=Namespace(class_path='model.CrossLayerTranscoder', init_args=Namespace(nonlinearity=Namespace(class_path='model.jumprelu.JumpReLU', init_args=Namespace(theta=0.03, bandwidth=1.0, n_layers=12, d_features=6144)), input_standardizer=Namespace(class_path='model.standardize.DimensionwiseInputStandardizer', init_args=Namespace(n_layers=12, activation_dim=768)), output_standardizer=Namespace(class_path='model.standardize.DimensionwiseOutputStandardizer', init_args=Namespace(n_layers=12, activation_dim=768)), d_acts=768, d_features=6144, n_layers=12)), lambda_sparsity=0.0004, c_sparsity=0.1, learning_rate=0.001, replacement_model_accuracy=Namespace(class_path='metrics.ReplacementModelAccuracy', init_args=Namespace(model_name='openai-community/gpt2', device_map='cuda:0', loader_batch_size=5)), compile=True))"
          ]
        }
      ],
      "source": [
        "# Path to the checkpoint\n",
        "checkpoint_path = \"checkpoints/clt.ckpt\"\n",
        "model = CrossLayerTranscoderModule.load_from_checkpoint(\n",
        "    checkpoint_path,\n",
        "    map_location=\"cuda:1\"  # Load to GPU 1\n",
        ")\n",
        "        \n",
        "model.eval()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Explore Model Architecture\n",
        "\n",
        "Let's examine the loaded model's architecture and hyperparameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if model is not None:\n",
        "    print(\"=== Model Hyperparameters ===\")\n",
        "    for key, value in model.hparams.items():\n",
        "        print(f\"{key}: {value}\")\n",
        "    \n",
        "    print(\"\\n=== Core Model Architecture ===\")\n",
        "    core_model = model.model\n",
        "    print(f\"Model type: {type(core_model)}\")\n",
        "    \n",
        "    if hasattr(core_model, 'n_layers'):\n",
        "        print(f\"Number of layers: {core_model.n_layers}\")\n",
        "    if hasattr(core_model, 'd_acts'):\n",
        "        print(f\"Activation dimension: {core_model.d_acts}\")\n",
        "    if hasattr(core_model, 'd_features'):\n",
        "        print(f\"Feature dimension: {core_model.d_features}\")\n",
        "    \n",
        "    print(\"\\n=== Model Parameters ===\")\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(f\"Total parameters: {total_params:,}\")\n",
        "    print(f\"Trainable parameters: {trainable_params:,}\")\n",
        "    \n",
        "    print(\"\\n=== Core Model Components ===\")\n",
        "    for name, module in core_model.named_children():\n",
        "        if hasattr(module, 'shape'):\n",
        "            print(f\"{name}: {module.shape}\")\n",
        "        else:\n",
        "            print(f\"{name}: {type(module).__name__}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Examine Model Weights\n",
        "\n",
        "Let's look at the encoder and decoder weights to understand the model structure.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if model is not None:\n",
        "    core_model = model.model\n",
        "    \n",
        "    # Check for encoder weights\n",
        "    if hasattr(core_model, 'W_enc'):\n",
        "        W_enc = core_model.W_enc\n",
        "        print(f\"Encoder weights shape: {W_enc.shape}\")\n",
        "        print(f\"Encoder weights dtype: {W_enc.dtype}\")\n",
        "        print(f\"Encoder weights device: {W_enc.device}\")\n",
        "        print(f\"Encoder weights range: [{W_enc.min():.6f}, {W_enc.max():.6f}]\")\n",
        "    \n",
        "    # Check for decoder weights\n",
        "    if hasattr(core_model, 'W_dec'):\n",
        "        W_dec = core_model.W_dec\n",
        "        print(f\"\\nDecoder weights shape: {W_dec.shape}\")\n",
        "        print(f\"Decoder weights dtype: {W_dec.dtype}\")\n",
        "        print(f\"Decoder weights device: {W_dec.device}\")\n",
        "        print(f\"Decoder weights range: [{W_dec.min():.6f}, {W_dec.max():.6f}]\")\n",
        "    \n",
        "    # Check for mask\n",
        "    if hasattr(core_model, 'mask'):\n",
        "        mask = core_model.mask\n",
        "        print(f\"\\nMask shape: {mask.shape}\")\n",
        "        print(f\"Mask dtype: {mask.dtype}\")\n",
        "        print(f\"Mask non-zero elements: {mask.sum().item()} / {mask.numel()} ({100*mask.sum().item()/mask.numel():.1f}%)\")\n",
        "    \n",
        "    # Check bias\n",
        "    if hasattr(core_model, 'b_dec'):\n",
        "        b_dec = core_model.b_dec\n",
        "        print(f\"\\nDecoder bias shape: {b_dec.shape}\")\n",
        "        print(f\"Decoder bias range: [{b_dec.min():.6f}, {b_dec.max():.6f}]\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Visualize Model Structure\n",
        "\n",
        "Create some visualizations to better understand the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if model is not None and hasattr(model.model, 'mask'):\n",
        "    mask = model.model.mask.detach().cpu().numpy()\n",
        "    \n",
        "    # Plot the mask structure\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.imshow(mask, cmap='Blues', aspect='auto')\n",
        "    plt.title('CrossLayer Transcoder Mask Structure')\n",
        "    plt.xlabel('To Layer')\n",
        "    plt.ylabel('From Layer')\n",
        "    plt.colorbar(label='Mask Value')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Show mask statistics per layer\n",
        "    mask_sum_per_layer = mask.sum(axis=1)\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.bar(range(len(mask_sum_per_layer)), mask_sum_per_layer)\n",
        "    plt.title('Number of Active Connections per Layer')\n",
        "    plt.xlabel('Layer')\n",
        "    plt.ylabel('Number of Active Connections')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Model Forward Pass Demo\n",
        "\n",
        "Demonstrate how to use the model for inference with dummy data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if model is not None:\n",
        "    # Create dummy input data\n",
        "    batch_size = 4\n",
        "    \n",
        "    # Get model dimensions\n",
        "    if hasattr(model.model, 'n_layers') and hasattr(model.model, 'd_acts'):\n",
        "        n_layers = model.model.n_layers\n",
        "        d_acts = model.model.d_acts\n",
        "        \n",
        "        print(f\"Creating dummy input with shape: ({batch_size}, {n_layers}, {d_acts})\")\n",
        "        \n",
        "        # Create normalized random input\n",
        "        dummy_input = torch.randn(batch_size, n_layers, d_acts)\n",
        "        \n",
        "        # Run forward pass\n",
        "        with torch.no_grad():\n",
        "            try:\n",
        "                features, reconstructions = model(dummy_input)\n",
        "                \n",
        "                print(f\"\\n=== Forward Pass Results ===\")\n",
        "                print(f\"Input shape: {dummy_input.shape}\")\n",
        "                print(f\"Features shape: {features.shape}\")\n",
        "                print(f\"Reconstructions shape: {reconstructions.shape}\")\n",
        "                \n",
        "                # Compute reconstruction error\n",
        "                if hasattr(model.model, 'output_standardizer'):\n",
        "                    # If we have standardizers, we need to handle normalization\n",
        "                    print(\"\\nNote: Model uses standardizers - reconstruction comparison may not be direct\")\n",
        "                else:\n",
        "                    mse = torch.mean((dummy_input - reconstructions)**2)\n",
        "                    print(f\"\\nReconstruction MSE: {mse.item():.6f}\")\n",
        "                \n",
        "                # Feature statistics\n",
        "                print(f\"\\n=== Feature Statistics ===\")\n",
        "                print(f\"Features mean: {features.mean().item():.6f}\")\n",
        "                print(f\"Features std: {features.std().item():.6f}\")\n",
        "                print(f\"Features sparsity (% zeros): {100 * (features == 0).float().mean().item():.1f}%\")\n",
        "                print(f\"Features L0 norm (avg active per sample): {(features > 0).float().sum(dim=[1,2]).mean().item():.1f}\")\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"❌ Error during forward pass: {e}\")\n",
        "                print(\"The model may need initialization or specific input formatting.\")\n",
        "    else:\n",
        "        print(\"Could not determine model dimensions for demo.\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Access Individual Components\n",
        "\n",
        "Show how to access different parts of the model for analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if model is not None:\n",
        "    core_model = model.model\n",
        "    \n",
        "    print(\"=== Available Model Components ===\")\n",
        "    \n",
        "    # Core transcoder\n",
        "    print(f\"Core transcoder: {type(core_model)}\")\n",
        "    \n",
        "    # Standardizers\n",
        "    if hasattr(core_model, 'input_standardizer'):\n",
        "        print(f\"Input standardizer: {type(core_model.input_standardizer)}\")\n",
        "        if hasattr(core_model.input_standardizer, 'is_initialized'):\n",
        "            print(f\"  - Initialized: {core_model.input_standardizer.is_initialized}\")\n",
        "    \n",
        "    if hasattr(core_model, 'output_standardizer'):\n",
        "        print(f\"Output standardizer: {type(core_model.output_standardizer)}\")\n",
        "        if hasattr(core_model.output_standardizer, 'is_initialized'):\n",
        "            print(f\"  - Initialized: {core_model.output_standardizer.is_initialized}\")\n",
        "    \n",
        "    # Activation function\n",
        "    if hasattr(core_model, 'activation'):\n",
        "        print(f\"Activation function: {type(core_model.activation)}\")\n",
        "        if hasattr(core_model.activation, 'threshold'):\n",
        "            print(f\"  - Threshold shape: {core_model.activation.threshold.shape}\")\n",
        "            print(f\"  - Threshold range: [{core_model.activation.threshold.min():.6f}, {core_model.activation.threshold.max():.6f}]\")\n",
        "    \n",
        "    print(\"\\n=== Training Configuration ===\")\n",
        "    print(f\"Lambda sparsity: {model._lambda}\")\n",
        "    print(f\"C sparsity: {model.c}\")\n",
        "    print(f\"Learning rate: {model.learning_rate}\")\n",
        "    print(f\"Compile mode: {model.compile}\")\n",
        "    \n",
        "    print(\"\\n=== Model State ===\")\n",
        "    print(f\"Training: {model.training}\")\n",
        "    print(f\"Device: {next(model.parameters()).device}\")\n",
        "    print(f\"Dtype: {next(model.parameters()).dtype}\")\n",
        "\n",
        "print(\"\\nModel loading and exploration complete!\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
