# lightning.pytorch==2.5.2
seed_everything: 42
trainer:
  accelerator: gpu
  strategy: auto
  devices: 1
  num_nodes: 1
  precision: 16-mixed
  logger: false
  callbacks:
  - class_path: utils.callbacks.EndOfTrainingCheckpointCallback
    init_args:
      checkpoint_dir: checkpoints
  - class_path: utils.callbacks.TensorBoardProfilerCallback
    init_args:
      log_dir: log/profiler
  fast_dev_run: false
  max_epochs: null
  min_epochs: null
  max_steps: 25
  min_steps: null
  max_time: null
  limit_train_batches: null
  limit_val_batches: 1
  limit_test_batches: null
  limit_predict_batches: null
  overfit_batches: 0.0
  val_check_interval: 200
  check_val_every_n_epoch: null
  num_sanity_val_steps: 0
  log_every_n_steps: null
  enable_checkpointing: false
  enable_progress_bar: null
  enable_model_summary: null
  accumulate_grad_batches: 1
  gradient_clip_val: null
  gradient_clip_algorithm: null
  deterministic: null
  benchmark: null
  inference_mode: true
  use_distributed_sampler: true
  profiler: null
  detect_anomaly: false
  barebones: false
  plugins: null
  sync_batchnorm: false
  reload_dataloaders_every_n_epochs: 0
  default_root_dir: null
  model_registry: null
model:
  class_path: model.CrossLayerTranscoderModule
  init_args:
    d_acts: 768
    d_features: 6144
    nonlinearity_theta: 0.03
    nonlinearity_bandwidth: 1.0
    activation_dim: 768
    lambda_sparsity: 0.0004
    c_sparsity: 0.1
    learning_rate: 0.001
    replacement_model_accuracy:
      class_path: metrics.ReplacementModelAccuracy
      init_args:
        model_name: openai-community/gpt2
        device_map: cuda:0
        loader_batch_size: 5
    compile: true
data:
  class_path: data.ActivationDataModule
  init_args:
    buffer_size: 2000000
    n_in_out: 2
    n_layers: 12
    activation_dim: 768
    dtype: float16
    max_batch_size: 50000
    model_name: openai-community/gpt2
    model_dtype: float32
    dataset_name: Skylion007/openwebtext
    dataset_split: train
    max_sequence_length: 1024
    generation_batch_size: 2
    refresh_interval: 0.1
    shared_memory_name: activation_buffer
    timeout_seconds: 30
    init_file: /var/local/glang/activations/clt-activations-10M-shuffled_fp16.h5
    batch_size: 4000
    num_workers: 20
    prefetch_factor: 2
    shuffle: true
    persistent_workers: true
    pin_memory: true
    use_shared_memory: true
    device_map: cuda:2
    wandb_logging:
      enabled: true
      project: crosslayer-transcoder
      group: null
      run_name: data-generator
      tags:
      - data-generation
      save_dir: ./wandb
      log_interval: 5.0
optimizer: null
lr_scheduler: null
return_predictions: null
ckpt_path: checkpoints/clt.ckpt
