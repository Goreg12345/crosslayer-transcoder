# Test config to verify double compilation bug
# Copy of jumprelu-clt-long.yaml but with compile: false

seed_everything: 42

trainer:
  max_steps: 10_000  # Short test
  val_check_interval: 1000
  limit_val_batches: 1
  check_val_every_n_epoch: null
  enable_checkpointing: false
  num_sanity_val_steps: 0
  precision: "16-mixed"
  accelerator: "gpu"
  devices: [1]
  accumulate_grad_batches: 1
  logger:
    class_path: lightning.pytorch.loggers.WandbLogger
    init_args:
      project: "debug-jumprelu"
      name: "test-no-double-compile"
      save_dir: "./wandb"
  callbacks:
    - class_path: utils.callbacks.EndOfTrainingCheckpointCallback
      init_args:
        checkpoint_dir: "checkpoints"

model:
  class_path: model.clt_lightning.JumpReLUCrossLayerTranscoderModule
  init_args:
    model:
      class_path: model.clt.CrossLayerTranscoder
      init_args:
        encoder:
          class_path: model.clt.Encoder
          init_args:
            d_acts: 768
            d_features: 16_000
            n_layers: 12
        decoder:
          class_path: model.clt.CrosslayerDecoder
          init_args:
            d_acts: 768
            d_features: 16_000
            n_layers: 12
        nonlinearity:
          class_path: model.jumprelu.JumpReLU
          init_args:
            theta: 0.03
            bandwidth: 1.0
            n_layers: 12
            d_features: 16_000
        input_standardizer:
          class_path: model.standardize.DimensionwiseInputStandardizer
          init_args:
            n_layers: 12
            activation_dim: 768
        output_standardizer:
          class_path: model.standardize.DimensionwiseOutputStandardizer
          init_args:
            n_layers: 12
            activation_dim: 768

    replacement_model:
      class_path: metrics.replacement_model_accuracy.ReplacementModelAccuracy
      init_args:
        model_name: "openai-community/gpt2"
        device_map: "cuda:2"
        loader_batch_size: 2
    
    dead_features:
      class_path: metrics.dead_features.DeadFeatures
      init_args:
        n_features: 16_000
        n_layers: 12
        return_per_layer: true
        return_log_freqs: true
        return_neuron_indices: true
    
    # Training parameters
    learning_rate: 1e-4
    compile: false  # ‚Üê DISABLE double compilation to test theory
    lr_decay_step: 90_000
    lr_decay_factor: 0.1
    lambda_sparsity: 0.0004
    c_sparsity: 1

    compute_dead_features: true
    compute_dead_features_every: 500

data:
  class_path: data.datamodule.ActivationDataModule
  init_args:
    buffer_size: 3_000_000
    n_in_out: 2
    n_layers: 12
    activation_dim: 768
    dtype: "float16"
    max_batch_size: 50000
    model_name: "openai-community/gpt2"
    model_dtype: "float32"
    dataset_name: "Skylion007/openwebtext"
    dataset_split: "train"
    max_sequence_length: 1024
    generation_batch_size: 10
    refresh_interval: 0.1
    shared_memory_name: "activation_buffer"
    timeout_seconds: 30
    init_file: "/var/local/glang/activations/clt-activations-10M-shuffled_fp16.h5"
    batch_size: 2000
    num_workers: 10
    prefetch_factor: 2
    shuffle: true
    persistent_workers: true
    pin_memory: true
    minimum_fill_threshold: 0.01
    use_shared_memory: true
    device_map: "cuda:0"
    wandb_logging:
      enabled: true
      project: "crosslayer-transcoder"
      group: null
      run_name: "data-generator"
      tags: ["data-generation"]
      save_dir: "./wandb"
      log_interval: 5.0

ckpt_path: null 